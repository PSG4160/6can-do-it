....................................................................![](https://noticon-static.tammolo.com/dgggcrkxq/image/upload/v1603679366/noticon/dcvetqndre7gda3ttijy.gif)....................................................................

---

# [AI_8ê¸°] 6ì¡° ë¨¸ì‹ ëŸ¬ë‹ & ë”¥ëŸ¬ë‹ íŒ€ê³¼ì œ 

| **íŒ€ì›** | âœ­ë°•ì„±ê·œ                                                                                            | ê¹€ë¯¼ì²                                                                                               | ì´ì‹œí—Œ                                                                                            | ë°•ìœ¤ì§€                                                                                             |
|:------:|:-----------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------:|
|        | ![á„‡á…¡á†¨á„‰á…¥á†¼á„€á…²á„‚á…µá†·](https://github.com/user-attachments/assets/40f97c52-c562-44b0-bef6-12289e149d27) | ![á„€á…µá†·á„†á…µá†«á„á…¥á†¯á„‚á…µá†·](https://github.com/user-attachments/assets/28b83bd5-13c2-4249-beab-64f7567e1816) | ![á„‹á…µá„‰á…µá„’á…¥á†«á„‚á…µá†·](https://github.com/user-attachments/assets/7b91b2aa-c113-44ed-8f41-e8df1ef7d06d) | ![á„‡á…¡á†¨á„‹á…²á†«á„Œá…µá„‚á…µá†·](https://github.com/user-attachments/assets/8d5be377-1a58-4f88-9ee2-176d1e1d162e) |
| **ì—­í• ** | ì˜¤ë¥˜ ì œì–´ ë° REPO ê´€ë¦¬                                                                                 | ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ                                                                                      | README.md ì‘ì„±                                                                                   | GIT ì¶©ëŒ ê´€ë¦¬ ë° íŒ€ì› ì½”ë“œ ë¦¬ë·°                                                                            |

## ê°œë°œ í™˜ê²½

![://noticon-static.tammolo.com/dgggcrkxq/image/upload/v1566791609/noticon/nen1y11gazeqhejw7nmhttps1.png](https://noticon-static.tammolo.com/dgggcrkxq/image/upload/v1566791609/noticon/nen1y11gazeqhejw7nm1.png) ![https://noticon-static.tammolo.com/dgggcrkxq/image/upload/v1626170585/noticon/uqui2rrxtt26ngudnhdu.png](https://noticon-static.tammolo.com/dgggcrkxq/image/upload/v1626170585/noticon/uqui2rrxtt26ngudnhdu.png)![https://noticon-static.tammolo.com/dgggcrkxq/image/upload/v1632975248/noticon/sph4ujixspcnhzpw8zky.png](https://noticon-static.tammolo.com/dgggcrkxq/image/upload/v1632975248/noticon/sph4ujixspcnhzpw8zky.png)

## ì§„í–‰í•œ í”„ë¡œì íŠ¸ ëª©ë¡

- ### [íƒ€ì´íƒ€ë‹‰ ìƒì¡´ì ì˜ˆì¸¡](#%EF%B8%8F-íƒ€ì´íƒ€ë‹‰-ìƒì¡´ì-ì˜ˆì¸¡)

- ### [ì˜í™” ë¦¬ë·° ê°ì„± ë¶„ì„](#-ì˜í™”-ë¦¬ë·°-ê°ì„±-ë¶„ì„)

### â›´ï¸ íƒ€ì´íƒ€ë‹‰ ìƒì¡´ì ì˜ˆì¸¡

> íƒ€ì´íƒ€ë‹‰ íƒ‘ìŠ¹ê° ë°ì´í„°ì…‹ì„ í™œìš©í•´ ìƒì¡´ìë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“œëŠ” í”„ë¡œì íŠ¸

#### ëª©í‘œ

<details>
<summary>1. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°</summary>

```python
import seaborn as sns

titanic = sns.load_dataset('titanic')
```

> titanic Dataset

<!-- dataset df -->

<div> 
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>survived</th>
      <th>pclass</th>
      <th>sex</th>
      <th>age</th>
      <th>sibsp</th>
      <th>parch</th>
      <th>fare</th>
      <th>embarked</th>
      <th>class</th>
      <th>who</th>
      <th>adult_male</th>
      <th>deck</th>
      <th>embark_town</th>
      <th>alive</th>
      <th>alone</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>S</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>no</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>C</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>C</td>
      <td>Cherbourg</td>
      <td>yes</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>S</td>
      <td>Third</td>
      <td>woman</td>
      <td>False</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>yes</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>S</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>C</td>
      <td>Southampton</td>
      <td>yes</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>S</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>no</td>
      <td>True</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>886</th>
      <td>0</td>
      <td>2</td>
      <td>male</td>
      <td>27.0</td>
      <td>0</td>
      <td>0</td>
      <td>13.0000</td>
      <td>S</td>
      <td>Second</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>no</td>
      <td>True</td>
    </tr>
    <tr>
      <th>887</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>19.0</td>
      <td>0</td>
      <td>0</td>
      <td>30.0000</td>
      <td>S</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>B</td>
      <td>Southampton</td>
      <td>yes</td>
      <td>True</td>
    </tr>
    <tr>
      <th>888</th>
      <td>0</td>
      <td>3</td>
      <td>female</td>
      <td>NaN</td>
      <td>1</td>
      <td>2</td>
      <td>23.4500</td>
      <td>S</td>
      <td>Third</td>
      <td>woman</td>
      <td>False</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>no</td>
      <td>False</td>
    </tr>
    <tr>
      <th>889</th>
      <td>1</td>
      <td>1</td>
      <td>male</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>30.0000</td>
      <td>C</td>
      <td>First</td>
      <td>man</td>
      <td>True</td>
      <td>C</td>
      <td>Cherbourg</td>
      <td>yes</td>
      <td>True</td>
    </tr>
    <tr>
      <th>890</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>32.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.7500</td>
      <td>Q</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Queenstown</td>
      <td>no</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
<p>891 rows Ã— 15 columns</p>
</div>
</details>
<br>

<details>
<summary>2. feature ë¶„ì„</summary>

> ë°ì´í„° í”„ë ˆì„ ì²« 5í–‰

```python
titanic.head()
```

<!-- head df -->

<div>
<table border="1" class="dataframe">
   <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>survived</th>
      <th>pclass</th>
      <th>sex</th>
      <th>age</th>
      <th>sibsp</th>
      <th>parch</th>
      <th>fare</th>
      <th>embarked</th>
      <th>class</th>
      <th>who</th>
      <th>adult_male</th>
      <th>deck</th>
      <th>embark_town</th>
      <th>alive</th>
      <th>alone</th>
    </tr>
   </thead>
   <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>S</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>no</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>C</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>C</td>
      <td>Cherbourg</td>
      <td>yes</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>S</td>
      <td>Third</td>
      <td>woman</td>
      <td>False</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>yes</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>S</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>C</td>
      <td>Southampton</td>
      <td>yes</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>S</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>no</td>
      <td>True</td>
    </tr>
   </tbody>
   </table>
   </div>

> í†µê³„ í™•ì¸ 

```python
titanic.describe()
```

`íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ ì£¼ìš” í•­ëª© (í–‰ row)`

| <span style="color:blue">**í•­ëª©**</span>       | <span style="color:blue">**ì„¤ëª…**</span> |
| -------------------------------------------- | -------------------------------------- |
| <span style="color:blue">**survived**</span> | ìŠ¹ê° ìƒì¡´ ì—¬ë¶€ (0 = ì‚¬ë§, 1 = ìƒì¡´)              |
| <span style="color:green">**pclass**</span>  | ê°ì‹¤ ë“±ê¸‰ (1 = 1ë“±ì„, 2 = 2ë“±ì„, 3 = 3ë“±ì„)      |
| <span style="color:purple">**age**</span>    | ìŠ¹ê° ë‚˜ì´                                  |
| <span style="color:orange">**sibsp**</span>  | ë™ë°˜í•œ í˜•ì œìë§¤ ë° ë°°ìš°ì ìˆ˜                       |
| <span style="color:orange">**parch**</span>  | ë™ë°˜í•œ ë¶€ëª¨ ë° ìë…€ ìˆ˜                          |
| <span style="color:teal">**fare**</span>     | ìŠ¹ê°ì´ ì§€ë¶ˆí•œ ìš´ì„ ê¸ˆì•¡                          |

`íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ ì£¼ìš” í†µê³„ (ì—´ Column)`

| <span style="color:blue">**ì§€í‘œ**</span>    | <span style="color:blue">**ì„¤ëª…**</span>  |
| ----------------------------------------- | --------------------------------------- |
| <span style="color:blue">**count**</span> | ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” í•­ëª©ì˜ ê°œìˆ˜ (ê²°ì¸¡ì¹˜ë¥¼ ì œì™¸í•œ ê°’ì˜ ê°œìˆ˜)       |
| <span style="color:green">**mean**</span> | ê°’ë“¤ì˜ í‰ê·                                   |
| <span style="color:purple">**std**</span> | í‘œì¤€í¸ì°¨ (ë°ì´í„°ê°€ í‰ê· ìœ¼ë¡œë¶€í„° ì–¼ë§ˆë‚˜ í¼ì ¸ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„)      |
| <span style="color:orange">**min**</span> | ë°ì´í„°ì˜ ìµœì†Œê°’                                |
| <span style="color:teal">**25%**</span>   | í•˜ìœ„ 25%ì— í•´ë‹¹í•˜ëŠ” ê°’. ë°ì´í„°ì˜ 25%ê°€ ì´ ê°’ë³´ë‹¤ ì‘ìŒ      |
| <span style="color:orange">**50%**</span> | ì¤‘ìœ„ê°’ (ë°ì´í„°ì˜ ì¤‘ê°„ ê°’). ë°ì´í„°ì˜ 50%ê°€ ì´ ê°’ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ìŒ |
| <span style="color:teal">**75%**</span>   | ìƒìœ„ 25%ì— í•´ë‹¹í•˜ëŠ” ê°’. ë°ì´í„°ì˜ 75%ê°€ ì´ ê°’ë³´ë‹¤ ì‘ìŒ      |
| <span style="color:red">**max**</span>    | ë°ì´í„°ì˜ ìµœëŒ€ê°’                                |

> ë°ì´í„°ì…‹ í†µê³„

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>survived</th>
      <th>pclass</th>
      <th>age</th>
      <th>sibsp</th>
      <th>parch</th>
      <th>fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>714.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.383838</td>
      <td>2.308642</td>
      <td>29.699118</td>
      <td>0.523008</td>
      <td>0.381594</td>
      <td>32.204208</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.486592</td>
      <td>0.836071</td>
      <td>14.526497</td>
      <td>1.102743</td>
      <td>0.806057</td>
      <td>49.693429</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.420000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>20.125000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>7.910400</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.000000</td>
      <td>3.000000</td>
      <td>28.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.454200</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>38.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>31.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>80.000000</td>
      <td>8.000000</td>
      <td>6.000000</td>
      <td>512.329200</td>
    </tr>
  </tbody>
</table>
</div>
<br>

</details>

<br>

<details>
<summary>
3. feature engineering
</summary>

> ê²°ì¸¡ì¹˜ ì²˜ë¦¬

`ê²°ì¸¡ì¹˜ ê°¯ìˆ˜ í™•ì¸`

```python
titanic.isnull().sum()
```

| <span style="color:blue">**í•­ëª©**</span>            | <span style="color:blue">**ê²°ì¸¡ì¹˜ ìˆ˜**</span> |
| ------------------------------------------------- | ----------------------------------------- |
| <span style="color:blue">**survived**</span>      | 0                                         |
| <span style="color:green">**pclass**</span>       | 0                                         |
| <span style="color:purple">**sex**</span>         | 0                                         |
| <span style="color:orange">**age**</span>         | 177                                       |
| <span style="color:teal">**sibsp**</span>         | 0                                         |
| <span style="color:blue">**parch**</span>         | 0                                         |
| <span style="color:green">**fare**</span>         | 0                                         |
| <span style="color:purple">**embarked**</span>    | 2                                         |
| <span style="color:orange">**class**</span>       | 0                                         |
| <span style="color:teal">**who**</span>           | 0                                         |
| <span style="color:blue">**adult_male**</span>    | 0                                         |
| <span style="color:green">**deck**</span>         | 688                                       |
| <span style="color:purple">**embark_town**</span> | 2                                         |
| <span style="color:orange">**alive**</span>       | 0                                         |
| <span style="color:teal">**alone**</span>         | 0                                         |

`ê²°ì¸¡ì¹˜ ê°’ ëŒ€ì²´`

```python
#Age(ë‚˜ì´)ì˜ ê²°ì¸¡ì¹˜ëŠ” ì¤‘ì•™ê°’ìœ¼ë¡œ, Embarked(ìŠ¹ì„  í•­êµ¬)ì˜ ê²°ì¸¡ì¹˜ëŠ” ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´. 
titanic['age'].fillna(titanic['age'].median(), inplace=True)
titanic['embarked'].fillna(titanic['embarked'].mode()[0], inplace=True)

# ëŒ€ì²´í•œ í›„ì—, ëŒ€ì²´ ê²°ê³¼ë¥¼ isnull() í•¨ìˆ˜ì™€ sum()  í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ í™•ì¸
print(titanic['age'].isnull().sum())
print(titanic['embarked'].isnull().sum())
```

`ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ì¸ì½”ë”©`

```python
# Sex(ì„±ë³„)ë¥¼ ë‚¨ìëŠ” 0, ì—¬ìëŠ” 1ë¡œ ë³€í™˜. 
# alive(ìƒì¡´ì—¬ë¶€)ë¥¼ TrueëŠ” 1, FalseëŠ” 0ìœ¼ë¡œ ë³€í™˜. 
# Embarked(ìŠ¹ì„  í•­êµ¬)ëŠ” â€˜Câ€™ëŠ” 0ìœ¼ë¡œ, QëŠ” 1ìœ¼ë¡œ, â€˜Sâ€™ëŠ” 2ë¡œ ë³€í™˜. 
# ëª¨ë‘ ë³€í™˜í•œ í›„ì—, ë³€í™˜ ê²°ê³¼ë¥¼ head í•¨ìˆ˜ë¥¼ ì´ìš©í•´ í™•ì¸. 


titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})
titanic['alive'] = titanic['alive'].map({'no': 1, 'yes': 0})
titanic['embarked'] = titanic['embarked'].map({'C': 0, 'Q': 1, 'S': 2,})

print(titanic['sex'].head())
print(titanic['alive'].head())
print(titanic['embarked'].head())
```

`ìƒˆë¡œìš´ feature ìƒì„±`

```python
#Sibsp , Parch ë¥¼ í†µí•´ family_size ìƒì„±
#ìƒˆë¡œìš´ Featureë¥¼ headí•¨ìˆ˜ë¥¼ ì´ìš©í•´ í™•ì¸

titanic['family_size'] = titanic['sibsp'] + titanic['parch'] + 1

print(titanic['family_size'].head())
```

> ê°€ì¡±êµ¬ì„±ì› í•­ëª© ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>survived</th>
      <th>pclass</th>
      <th>sex</th>
      <th>age</th>
      <th>sibsp</th>
      <th>parch</th>
      <th>fare</th>
      <th>embarked</th>
      <th>class</th>
      <th>who</th>
      <th>adult_male</th>
      <th>deck</th>
      <th>embark_town</th>
      <th>alive</th>
      <th>alone</th>
      <th>family_size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>2</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>1</td>
      <td>False</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>0</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>C</td>
      <td>Cherbourg</td>
      <td>0</td>
      <td>False</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>2</td>
      <td>Third</td>
      <td>woman</td>
      <td>False</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>0</td>
      <td>True</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>2</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>C</td>
      <td>Southampton</td>
      <td>0</td>
      <td>False</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>2</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>1</td>
      <td>True</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>886</th>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>27.0</td>
      <td>0</td>
      <td>0</td>
      <td>13.0000</td>
      <td>2</td>
      <td>Second</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>1</td>
      <td>True</td>
      <td>1</td>
    </tr>
    <tr>
      <th>887</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>19.0</td>
      <td>0</td>
      <td>0</td>
      <td>30.0000</td>
      <td>2</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>B</td>
      <td>Southampton</td>
      <td>0</td>
      <td>True</td>
      <td>1</td>
    </tr>
    <tr>
      <th>888</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>28.0</td>
      <td>1</td>
      <td>2</td>
      <td>23.4500</td>
      <td>2</td>
      <td>Third</td>
      <td>woman</td>
      <td>False</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>1</td>
      <td>False</td>
      <td>4</td>
    </tr>
    <tr>
      <th>889</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>30.0000</td>
      <td>0</td>
      <td>First</td>
      <td>man</td>
      <td>True</td>
      <td>C</td>
      <td>Cherbourg</td>
      <td>0</td>
      <td>True</td>
      <td>1</td>
    </tr>
    <tr>
      <th>890</th>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>32.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.7500</td>
      <td>1</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Queenstown</td>
      <td>1</td>
      <td>True</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>891 rows Ã— 16 columns</p>
</div>

</details>
<br>

<details>
<summary>
4. ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸° (Logistic Regression, Decision Tree, XGBoost)  
</summary>

`ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì§„í–‰`

```py
#featureì™€ target ë¶„ë¦¬

titanic = titanic[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'family_size']]
X = titanic.drop('survived', axis=1) # feature
y = titanic['survived'] # target

# xëŠ” ìŠ¹ê°ì˜ ìƒì¡´ ì—¬ë¶€ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ëª¨ë“  ì—´ì„ í•™ìŠµì— ì‚¬ìš©í•  íŠ¹ì§•
# yëŠ” ìŠ¹ê°ì´ ìƒì¡´í–ˆëŠ”ì§€ì˜ ì—¬ë¶€
# xë¡œ yë¥¼ ì˜ˆì¸¡
```

> Logistic Regression

```py
# Logistic Regression

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ë°ì´í„° ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = LogisticRegression()
model.fit(X_train, y_train)

# ì˜ˆì¸¡
y_pred = model.predict(X_test)

# í‰ê°€
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
```

> ğŸ” Logistic Regression ê²°ê³¼ ìš”ì•½

| **ì§€í‘œ**                | **í¬ìƒì (0)**                      | **ìƒì¡´ì (1)**                      |
| --------------------- | -------------------------------- | -------------------------------- |
| **ì •ë°€ë„ (Precision)**   | 0.82 (ëª¨ë¸ì´ ì˜ˆì¸¡í•œ 'í¬ìƒì' ì¤‘ ì‹¤ì œ í¬ìƒì ë¹„ìœ¨) | 0.78 (ëª¨ë¸ì´ ì˜ˆì¸¡í•œ 'ìƒì¡´ì' ì¤‘ ì‹¤ì œ ìƒì¡´ì ë¹„ìœ¨) |
| **ì¬í˜„ìœ¨ (Recall)**      | 0.86 (ì‹¤ì œ í¬ìƒì ì¤‘ ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨)       | 0.73 (ì‹¤ì œ ìƒì¡´ì ì¤‘ ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨)       |
| **F1-ìŠ¤ì½”ì–´ (F1-Score)** | 0.84 (ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê· )            | 0.76 (ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê· )            |
| **ì§€ì› (Support)**      | 105                              | 74                               |

| **í‰ê·  ì§€í‘œ**          | **ê°’**                                         |
| ------------------ | --------------------------------------------- |
| **ì •í™•ë„ (Accuracy)** | 0.80 (ì „ì²´ ë°ì´í„°ì—ì„œ ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨)                    |
| **Macro í‰ê· **       | Precision: 0.80, Recall: 0.79, F1-Score: 0.80 |
| **Weighted í‰ê· **    | Precision: 0.80, Recall: 0.80, F1-Score: 0.80 |

**ìš”ì•½**: Logistic Regression ëª¨ë¸ì€ ì•½ 80%ì˜ ì •í™•ë„ë¥¼ ë³´ì´ë©°, í¬ìƒìë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ìˆì–´ì„œ ì¬í˜„ìœ¨ì´ ë†’ì•„(0.86) í¬ìƒìë¥¼ ì˜ ì˜ˆì¸¡. ìƒì¡´ìì— ëŒ€í•œ ì¬í˜„ìœ¨ì€ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì•„(0.73) ìƒì¡´ìë¥¼ ë†“ì¹˜ëŠ” ê²½í–¥ì´ ì•½ê°„ ìˆìŒ.

> Decision Tree

```py
#Decision Tree

from sklearn.tree import DecisionTreeClassifier  # Decision Tree ë¶„ë¥˜ê¸°
# ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ë°ì´í„° ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)

# ì˜ˆì¸¡
y_pred = model.predict(X_test)

# í‰ê°€
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
```

> ğŸ” Decision Tree ëª¨ë¸ ê²°ê³¼ ìš”ì•½

| **ì§€í‘œ**                | **í¬ìƒì (0)**                      | **ìƒì¡´ì (1)**                      |
| --------------------- | -------------------------------- | -------------------------------- |
| **ì •ë°€ë„ (Precision)**   | 0.83 (ëª¨ë¸ì´ ì˜ˆì¸¡í•œ 'í¬ìƒì' ì¤‘ ì‹¤ì œ í¬ìƒì ë¹„ìœ¨) | 0.70 (ëª¨ë¸ì´ ì˜ˆì¸¡í•œ 'ìƒì¡´ì' ì¤‘ ì‹¤ì œ ìƒì¡´ì ë¹„ìœ¨) |
| **ì¬í˜„ìœ¨ (Recall)**      | 0.76 (ì‹¤ì œ í¬ìƒì ì¤‘ ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨)       | 0.78 (ì‹¤ì œ ìƒì¡´ì ì¤‘ ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨)       |
| **F1-ìŠ¤ì½”ì–´ (F1-Score)** | 0.80 (ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê· )            | 0.74 (ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê· )            |
| **ì§€ì› (Support)**      | 105                              | 74                               |

| **í‰ê·  ì§€í‘œ**          | **ê°’**                                         |
| ------------------ | --------------------------------------------- |
| **ì •í™•ë„ (Accuracy)** | 0.77 (ì „ì²´ ë°ì´í„°ì—ì„œ ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨)                    |
| **Macro í‰ê· **       | Precision: 0.77, Recall: 0.77, F1-Score: 0.77 |
| **Weighted í‰ê· **    | Precision: 0.78, Recall: 0.77, F1-Score: 0.77 |

**ìš”ì•½**: Decision Tree ëª¨ë¸ì€ ì•½ 77%ì˜ ì •í™•ë„ë¥¼ ë³´ì´ë©°, í¬ìƒì ì˜ˆì¸¡ì—ì„œ ì •ë°€ë„ê°€ ë†’ì•„(0.83) í¬ìƒìë¥¼ ì˜ ë¶„ë¥˜í•˜ëŠ” ê²½í–¥ì´ ìˆìŒ. ìƒì¡´ìì˜ ì¬í˜„ìœ¨ì´ ë‹¤ì†Œ ë†’ì•„(0.78) ìƒì¡´ìë¥¼ ë†“ì¹˜ëŠ” ê²½ìš°ëŠ” ì ìœ¼ë‚˜, ì •ë°€ë„ê°€ í¬ìƒìì— ë¹„í•´ ë‚®ì•„(0.70) ìƒì¡´ì ì˜ˆì¸¡ ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ.

> XGBoost

```py
import xgboost as xgb
from sklearn.metrics import mean_squared_error

# ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ë°ì´í„° ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# XGBoost ëª¨ë¸ ìƒì„±
xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# ëª¨ë¸ í•™ìŠµ
xgb_model.fit(X_train_scaled, y_train)

# ì˜ˆì¸¡
y_pred_xgb = xgb_model.predict(X_test_scaled)

# í‰ê°€
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
print(f'XGBoost ëª¨ë¸ì˜ MSE: {mse_xgb}')
```

> ğŸ” XGBoost ëª¨ë¸ ê²°ê³¼ ìš”ì•½

| **ì§€í‘œ**                | **í¬ìƒì (0)**                      | **ìƒì¡´ì (1)**                      |
| --------------------- | -------------------------------- | -------------------------------- |
| **ì •ë°€ë„ (Precision)**   | 0.82 (ëª¨ë¸ì´ ì˜ˆì¸¡í•œ 'í¬ìƒì' ì¤‘ ì‹¤ì œ í¬ìƒì ë¹„ìœ¨) | 0.78 (ëª¨ë¸ì´ ì˜ˆì¸¡í•œ 'ìƒì¡´ì' ì¤‘ ì‹¤ì œ ìƒì¡´ì ë¹„ìœ¨) |
| **ì¬í˜„ìœ¨ (Recall)**      | 0.86 (ì‹¤ì œ í¬ìƒì ì¤‘ ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨)       | 0.73 (ì‹¤ì œ ìƒì¡´ì ì¤‘ ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨)       |
| **F1-ìŠ¤ì½”ì–´ (F1-Score)** | 0.84 (ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê· )            | 0.76 (ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê· )            |
| **ì§€ì› (Support)**      | 105                              | 74                               |

| **í‰ê·  ì§€í‘œ**          | **ê°’**                                         |
| ------------------ | --------------------------------------------- |
| **ì •í™•ë„ (Accuracy)** | 0.80 (ì „ì²´ ë°ì´í„°ì—ì„œ ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨)                    |
| **Macro í‰ê· **       | Precision: 0.80, Recall: 0.79, F1-Score: 0.80 |
| **Weighted í‰ê· **    | Precision: 0.80, Recall: 0.80, F1-Score: 0.80 |

**ìš”ì•½**: XGBoost ëª¨ë¸ì€ ì•½ 80%ì˜ ì •í™•ë„ë¥¼ ë³´ì´ë©°, í¬ìƒì ì˜ˆì¸¡ì—ì„œ ë†’ì€ ì¬í˜„ìœ¨(0.86)ë¡œ ì‹¤ì œ í¬ìƒìë¥¼ ì˜ ì‹ë³„í•˜ëŠ” ê²½í–¥ì´ ìˆìŒ. ìƒì¡´ì ì˜ˆì¸¡ì—ì„œëŠ” ì •ë°€ë„ê°€ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì•„(0.78) ìƒì¡´ìë¥¼ ë” ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•˜ë©°, ìƒì¡´ì ì¬í˜„ìœ¨ì€ 0.73ìœ¼ë¡œ ë‹¤ì†Œ ë‚®ìŒ. ì „ë°˜ì ìœ¼ë¡œ, XGBoost ëª¨ë¸ì€ í¬ìƒì ì‹ë³„ì— ê°•ì ì„ ë³´ì„.

</details>

<br>

<details>
<summary>
5. ëª¨ë¸ë³„ ì‹œê°í™” ìë£Œ (ì¶”ê°€)
</summary>

> í˜¼ë™ í–‰ë ¬ ì‹œê°í™”

```py
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# í˜¼ë™ í–‰ë ¬ ê³„ì‚°
cm = confusion_matrix(y_test, y_pred)

# í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Cancer', 'Cancer'], yticklabels=['Not Cancer', 'Cancer'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()
```

![confusionmatrix](https://github.com/user-attachments/assets/d377b51b-89ca-49db-a371-e93f2cb9580b)

> ê²°ì • íŠ¸ë¦¬ ì‹œê°í™”

```py
from sklearn.tree import plot_tree

# ê²°ì • íŠ¸ë¦¬ ì‹œê°í™”
plt.figure(figsize=(12, 8))
plot_tree(model, filled=True, feature_names=X.columns, class_names=['Not Survived', 'Survived'])
plt.title('Decision Tree Visualization')
plt.show()
```

![plottree](https://github.com/user-attachments/assets/22f0a9a5-fdff-4971-b30a-bbc9adbcc70d)

> XGBoost ì‹œê°í™”

`ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ê°’ì„ ë¹„êµí•˜ëŠ” ì‚°ì ë„ ì‹œê°í™”`

```py
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_xgb, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # ëŒ€ê°ì„  ì¶”ê°€
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted Values (XGBoost)')
plt.show()
```

![xgboost1](https://github.com/user-attachments/assets/2de22727-acbe-4130-a8a6-00df409d19be)

`XGBOOSTì˜ íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”`

```py
plt.figure(figsize=(12, 8))
xgb.plot_importance(xgb_model, importance_type='weight', max_num_features=10)
plt.title('Feature Importance (XGBoost)')
plt.show()
```

![xgboost2](https://github.com/user-attachments/assets/6171d604-b6b4-4f84-97ff-90693c919e21)

</details>
<br>
<details>
<summary>
6. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ (ì¶”ê°€)
</summary>

> ğŸ³ íƒ€ì´íƒ€ë‹‰ ìƒì¡´ì ì˜ˆì¸¡ ê²°ê³¼ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ

| **ëª¨ë¸**                  | **Accuracy** | <span style="color:red">**Precision (í¬ìƒì)**</span> | <span style="color:blue">**Precision (ìƒì¡´ì)**</span> | <span style="color:red">**Recall (í¬ìƒì)**</span> | <span style="color:blue">**Recall (ìƒì¡´ì)**</span> | <span style="color:red">**F1-Score (í¬ìƒì)**</span> | <span style="color:blue">**F1-Score (ìƒì¡´ì)**</span> |
| ----------------------- | ------------ | -------------------------------------------------- | --------------------------------------------------- | ----------------------------------------------- | ------------------------------------------------ | ------------------------------------------------- | -------------------------------------------------- |
| **Logistic Regression** | 0.8045       | <span style="color:red">0.82</span>                | <span style="color:blue">0.78</span>                | <span style="color:red">0.86</span>             | <span style="color:blue">0.73</span>             | <span style="color:red">0.84</span>               | <span style="color:blue">0.76</span>               |
| **Decision Tree**       | 0.7709       | <span style="color:red">0.83</span>                | <span style="color:blue">0.70</span>                | <span style="color:red">0.76</span>             | <span style="color:blue">0.78</span>             | <span style="color:red">0.80</span>               | <span style="color:blue">0.74</span>               |
| **XGBoost**             | 0.8045       | <span style="color:red">0.82</span>                | <span style="color:blue">0.78</span>                | <span style="color:red">0.86</span>             | <span style="color:blue">0.73</span>             | <span style="color:red">0.84</span>               | <span style="color:blue">0.76</span>               |

##### ìš”ì•½

- **Logistic Regression**ì™€ **XGBoost** ëª¨ë¸ì€ ë™ì¼í•œ ì •í™•ë„(80.45%)ë¡œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì„.
- **Decision Tree**ëŠ” ì •í™•ë„ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì§€ë§Œ, ìƒì¡´ì í´ë˜ìŠ¤(1)ì˜ Recallì´ ë†’ì•„ ìƒì¡´ìë¥¼ ì˜ ì˜ˆì¸¡.
- **Logistic Regression**ì™€ **XGBoost** ëª¨ë¸ì´ Decision Treeë³´ë‹¤ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„.

</details>

### ğŸ¬ ì˜í™” ë¦¬ë·° ê°ì„± ë¶„ì„

> ì˜í™” ë¦¬ë·° ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸ì •ì /ë¶€ì •ì  ê°ì •ì„ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“œëŠ” í”„ë¡œì íŠ¸Â 

#### ëª©í‘œ

1. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°

2. ë°ì´í„° ì „ì²˜ë¦¬

3. feature ë¶„ì„ (EDA)

4. ë¦¬ë·° ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸° (LSTM)

#### ì¶”ê°€ ëª©í‘œ

- [x] NLP ì´ìš©

- [x] ê¸ì • / ë¶€ì • ë¦¬ë·°ì˜ ì›Œë“œ í´ë¼ìš°ë“œ ê·¸ë ¤ë³´ê¸° 

#### 
