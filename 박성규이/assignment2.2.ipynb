{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f881cb2-3f20-4b69-a92c-9db10b96ad0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "117134lines [00:01, 85451.69lines/s] \n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_18016\\4051435007.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  reviews = pad_sequence([torch.tensor(r, dtype=torch.long) for r in reviews], batch_first=True)  # 정수형 텐서로 변환\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 10/1465, Loss: 1.4973\n",
      "Epoch 1/10, Batch 20/1465, Loss: 1.5300\n",
      "Epoch 1/10, Batch 30/1465, Loss: 1.3624\n",
      "Epoch 1/10, Batch 40/1465, Loss: 1.5449\n",
      "Epoch 1/10, Batch 50/1465, Loss: 1.4053\n",
      "Epoch 1/10, Batch 60/1465, Loss: 1.4345\n",
      "Epoch 1/10, Batch 70/1465, Loss: 1.4330\n",
      "Epoch 1/10, Batch 80/1465, Loss: 1.5878\n",
      "Epoch 1/10, Batch 90/1465, Loss: 1.4180\n",
      "Epoch 1/10, Batch 100/1465, Loss: 1.4489\n",
      "Epoch 1/10, Batch 110/1465, Loss: 1.5973\n",
      "Epoch 1/10, Batch 120/1465, Loss: 1.3844\n",
      "Epoch 1/10, Batch 130/1465, Loss: 1.3032\n",
      "Epoch 1/10, Batch 140/1465, Loss: 1.4516\n",
      "Epoch 1/10, Batch 150/1465, Loss: 1.3552\n",
      "Epoch 1/10, Batch 160/1465, Loss: 1.5032\n",
      "Epoch 1/10, Batch 170/1465, Loss: 1.5434\n",
      "Epoch 1/10, Batch 180/1465, Loss: 1.5632\n",
      "Epoch 1/10, Batch 190/1465, Loss: 1.4780\n",
      "Epoch 1/10, Batch 200/1465, Loss: 1.4367\n",
      "Epoch 1/10, Batch 210/1465, Loss: 1.4150\n",
      "Epoch 1/10, Batch 220/1465, Loss: 1.4449\n",
      "Epoch 1/10, Batch 230/1465, Loss: 1.3958\n",
      "Epoch 1/10, Batch 240/1465, Loss: 1.4321\n",
      "Epoch 1/10, Batch 250/1465, Loss: 1.3426\n",
      "Epoch 1/10, Batch 260/1465, Loss: 1.2663\n",
      "Epoch 1/10, Batch 270/1465, Loss: 1.2604\n",
      "Epoch 1/10, Batch 280/1465, Loss: 1.1881\n",
      "Epoch 1/10, Batch 290/1465, Loss: 1.0771\n",
      "Epoch 1/10, Batch 300/1465, Loss: 1.4672\n",
      "Epoch 1/10, Batch 310/1465, Loss: 1.1463\n",
      "Epoch 1/10, Batch 320/1465, Loss: 1.3834\n",
      "Epoch 1/10, Batch 330/1465, Loss: 1.2547\n",
      "Epoch 1/10, Batch 340/1465, Loss: 1.2269\n",
      "Epoch 1/10, Batch 350/1465, Loss: 1.0655\n",
      "Epoch 1/10, Batch 360/1465, Loss: 1.1865\n",
      "Epoch 1/10, Batch 370/1465, Loss: 1.4304\n",
      "Epoch 1/10, Batch 380/1465, Loss: 1.1440\n",
      "Epoch 1/10, Batch 390/1465, Loss: 1.3488\n",
      "Epoch 1/10, Batch 400/1465, Loss: 1.2218\n",
      "Epoch 1/10, Batch 410/1465, Loss: 1.1037\n",
      "Epoch 1/10, Batch 420/1465, Loss: 1.2151\n",
      "Epoch 1/10, Batch 430/1465, Loss: 1.2036\n",
      "Epoch 1/10, Batch 440/1465, Loss: 1.2094\n",
      "Epoch 1/10, Batch 450/1465, Loss: 1.1753\n",
      "Epoch 1/10, Batch 460/1465, Loss: 1.2384\n",
      "Epoch 1/10, Batch 470/1465, Loss: 1.2333\n",
      "Epoch 1/10, Batch 480/1465, Loss: 0.9794\n",
      "Epoch 1/10, Batch 490/1465, Loss: 1.1283\n",
      "Epoch 1/10, Batch 500/1465, Loss: 1.1509\n",
      "Epoch 1/10, Batch 510/1465, Loss: 1.0581\n",
      "Epoch 1/10, Batch 520/1465, Loss: 1.2156\n",
      "Epoch 1/10, Batch 530/1465, Loss: 1.1343\n",
      "Epoch 1/10, Batch 540/1465, Loss: 1.2476\n",
      "Epoch 1/10, Batch 550/1465, Loss: 1.2865\n",
      "Epoch 1/10, Batch 560/1465, Loss: 0.9922\n",
      "Epoch 1/10, Batch 570/1465, Loss: 1.0982\n",
      "Epoch 1/10, Batch 580/1465, Loss: 1.1680\n",
      "Epoch 1/10, Batch 590/1465, Loss: 1.1957\n",
      "Epoch 1/10, Batch 600/1465, Loss: 0.9786\n",
      "Epoch 1/10, Batch 610/1465, Loss: 1.0410\n",
      "Epoch 1/10, Batch 620/1465, Loss: 1.0788\n",
      "Epoch 1/10, Batch 630/1465, Loss: 1.2265\n",
      "Epoch 1/10, Batch 640/1465, Loss: 1.1341\n",
      "Epoch 1/10, Batch 650/1465, Loss: 1.2033\n",
      "Epoch 1/10, Batch 660/1465, Loss: 0.9649\n",
      "Epoch 1/10, Batch 670/1465, Loss: 0.9879\n",
      "Epoch 1/10, Batch 680/1465, Loss: 1.1447\n",
      "Epoch 1/10, Batch 690/1465, Loss: 1.0534\n",
      "Epoch 1/10, Batch 700/1465, Loss: 1.0328\n",
      "Epoch 1/10, Batch 710/1465, Loss: 1.0442\n",
      "Epoch 1/10, Batch 720/1465, Loss: 1.0572\n",
      "Epoch 1/10, Batch 730/1465, Loss: 1.2002\n",
      "Epoch 1/10, Batch 740/1465, Loss: 0.8766\n",
      "Epoch 1/10, Batch 750/1465, Loss: 1.0356\n",
      "Epoch 1/10, Batch 760/1465, Loss: 1.1650\n",
      "Epoch 1/10, Batch 770/1465, Loss: 1.1199\n",
      "Epoch 1/10, Batch 780/1465, Loss: 0.9398\n",
      "Epoch 1/10, Batch 790/1465, Loss: 1.0798\n",
      "Epoch 1/10, Batch 800/1465, Loss: 1.1631\n",
      "Epoch 1/10, Batch 810/1465, Loss: 1.0244\n",
      "Epoch 1/10, Batch 820/1465, Loss: 0.8952\n",
      "Epoch 1/10, Batch 830/1465, Loss: 1.1039\n",
      "Epoch 1/10, Batch 840/1465, Loss: 1.1255\n",
      "Epoch 1/10, Batch 850/1465, Loss: 1.1384\n",
      "Epoch 1/10, Batch 860/1465, Loss: 1.0211\n",
      "Epoch 1/10, Batch 870/1465, Loss: 1.1985\n",
      "Epoch 1/10, Batch 880/1465, Loss: 1.2075\n",
      "Epoch 1/10, Batch 890/1465, Loss: 1.1392\n",
      "Epoch 1/10, Batch 900/1465, Loss: 1.1274\n",
      "Epoch 1/10, Batch 910/1465, Loss: 1.1348\n",
      "Epoch 1/10, Batch 920/1465, Loss: 1.0821\n",
      "Epoch 1/10, Batch 930/1465, Loss: 1.1928\n",
      "Epoch 1/10, Batch 940/1465, Loss: 1.0882\n",
      "Epoch 1/10, Batch 950/1465, Loss: 1.0698\n",
      "Epoch 1/10, Batch 960/1465, Loss: 1.2047\n",
      "Epoch 1/10, Batch 970/1465, Loss: 0.8187\n",
      "Epoch 1/10, Batch 980/1465, Loss: 1.0094\n",
      "Epoch 1/10, Batch 990/1465, Loss: 1.1008\n",
      "Epoch 1/10, Batch 1000/1465, Loss: 1.0847\n",
      "Epoch 1/10, Batch 1010/1465, Loss: 1.2492\n",
      "Epoch 1/10, Batch 1020/1465, Loss: 1.0850\n",
      "Epoch 1/10, Batch 1030/1465, Loss: 1.0591\n",
      "Epoch 1/10, Batch 1040/1465, Loss: 1.0285\n",
      "Epoch 1/10, Batch 1050/1465, Loss: 1.1271\n",
      "Epoch 1/10, Batch 1060/1465, Loss: 0.8141\n",
      "Epoch 1/10, Batch 1070/1465, Loss: 0.7452\n",
      "Epoch 1/10, Batch 1080/1465, Loss: 1.3506\n",
      "Epoch 1/10, Batch 1090/1465, Loss: 1.0719\n",
      "Epoch 1/10, Batch 1100/1465, Loss: 1.0505\n",
      "Epoch 1/10, Batch 1110/1465, Loss: 1.1755\n",
      "Epoch 1/10, Batch 1120/1465, Loss: 0.9961\n",
      "Epoch 1/10, Batch 1130/1465, Loss: 0.9375\n",
      "Epoch 1/10, Batch 1140/1465, Loss: 1.0775\n",
      "Epoch 1/10, Batch 1150/1465, Loss: 1.0128\n",
      "Epoch 1/10, Batch 1160/1465, Loss: 0.9383\n",
      "Epoch 1/10, Batch 1170/1465, Loss: 0.9749\n",
      "Epoch 1/10, Batch 1180/1465, Loss: 1.1173\n",
      "Epoch 1/10, Batch 1190/1465, Loss: 1.0611\n",
      "Epoch 1/10, Batch 1200/1465, Loss: 0.9774\n",
      "Epoch 1/10, Batch 1210/1465, Loss: 1.2343\n",
      "Epoch 1/10, Batch 1220/1465, Loss: 1.2226\n",
      "Epoch 1/10, Batch 1230/1465, Loss: 0.9815\n",
      "Epoch 1/10, Batch 1240/1465, Loss: 0.9349\n",
      "Epoch 1/10, Batch 1250/1465, Loss: 0.8540\n",
      "Epoch 1/10, Batch 1260/1465, Loss: 0.9943\n",
      "Epoch 1/10, Batch 1270/1465, Loss: 1.1022\n",
      "Epoch 1/10, Batch 1280/1465, Loss: 0.9540\n",
      "Epoch 1/10, Batch 1290/1465, Loss: 0.9228\n",
      "Epoch 1/10, Batch 1300/1465, Loss: 1.2192\n",
      "Epoch 1/10, Batch 1310/1465, Loss: 0.9892\n",
      "Epoch 1/10, Batch 1320/1465, Loss: 1.0035\n",
      "Epoch 1/10, Batch 1330/1465, Loss: 0.9027\n",
      "Epoch 1/10, Batch 1340/1465, Loss: 0.9857\n",
      "Epoch 1/10, Batch 1350/1465, Loss: 0.9468\n",
      "Epoch 1/10, Batch 1360/1465, Loss: 1.3002\n",
      "Epoch 1/10, Batch 1370/1465, Loss: 1.0112\n",
      "Epoch 1/10, Batch 1380/1465, Loss: 1.1345\n",
      "Epoch 1/10, Batch 1390/1465, Loss: 0.9905\n",
      "Epoch 1/10, Batch 1400/1465, Loss: 0.9474\n",
      "Epoch 1/10, Batch 1410/1465, Loss: 0.9628\n",
      "Epoch 1/10, Batch 1420/1465, Loss: 1.3927\n",
      "Epoch 1/10, Batch 1430/1465, Loss: 1.0703\n",
      "Epoch 1/10, Batch 1440/1465, Loss: 1.1172\n",
      "Epoch 1/10, Batch 1450/1465, Loss: 1.0983\n",
      "Epoch 1/10, Batch 1460/1465, Loss: 1.0144\n",
      "Epoch [1/10], Average Loss: 1.1517\n",
      "Epoch 2/10, Batch 10/1465, Loss: 0.8674\n",
      "Epoch 2/10, Batch 20/1465, Loss: 0.9044\n",
      "Epoch 2/10, Batch 30/1465, Loss: 0.9463\n",
      "Epoch 2/10, Batch 40/1465, Loss: 1.0247\n",
      "Epoch 2/10, Batch 50/1465, Loss: 0.8928\n",
      "Epoch 2/10, Batch 60/1465, Loss: 1.2160\n",
      "Epoch 2/10, Batch 70/1465, Loss: 1.1872\n",
      "Epoch 2/10, Batch 80/1465, Loss: 0.9975\n",
      "Epoch 2/10, Batch 90/1465, Loss: 0.9898\n",
      "Epoch 2/10, Batch 100/1465, Loss: 1.1939\n",
      "Epoch 2/10, Batch 110/1465, Loss: 0.9677\n",
      "Epoch 2/10, Batch 120/1465, Loss: 0.7516\n",
      "Epoch 2/10, Batch 130/1465, Loss: 1.0500\n",
      "Epoch 2/10, Batch 140/1465, Loss: 0.8577\n",
      "Epoch 2/10, Batch 150/1465, Loss: 1.0395\n",
      "Epoch 2/10, Batch 160/1465, Loss: 1.0106\n",
      "Epoch 2/10, Batch 170/1465, Loss: 0.8532\n",
      "Epoch 2/10, Batch 180/1465, Loss: 0.7968\n",
      "Epoch 2/10, Batch 190/1465, Loss: 0.8099\n",
      "Epoch 2/10, Batch 200/1465, Loss: 1.1612\n",
      "Epoch 2/10, Batch 210/1465, Loss: 1.1121\n",
      "Epoch 2/10, Batch 220/1465, Loss: 1.0593\n",
      "Epoch 2/10, Batch 230/1465, Loss: 1.0573\n",
      "Epoch 2/10, Batch 240/1465, Loss: 0.7802\n",
      "Epoch 2/10, Batch 250/1465, Loss: 1.2974\n",
      "Epoch 2/10, Batch 260/1465, Loss: 0.9643\n",
      "Epoch 2/10, Batch 270/1465, Loss: 1.1035\n",
      "Epoch 2/10, Batch 280/1465, Loss: 0.9388\n",
      "Epoch 2/10, Batch 290/1465, Loss: 1.0518\n",
      "Epoch 2/10, Batch 300/1465, Loss: 0.7298\n",
      "Epoch 2/10, Batch 310/1465, Loss: 0.8947\n",
      "Epoch 2/10, Batch 320/1465, Loss: 1.0686\n",
      "Epoch 2/10, Batch 330/1465, Loss: 0.8865\n",
      "Epoch 2/10, Batch 340/1465, Loss: 0.7550\n",
      "Epoch 2/10, Batch 350/1465, Loss: 1.1193\n",
      "Epoch 2/10, Batch 360/1465, Loss: 0.9586\n",
      "Epoch 2/10, Batch 370/1465, Loss: 0.9434\n",
      "Epoch 2/10, Batch 380/1465, Loss: 0.8550\n",
      "Epoch 2/10, Batch 390/1465, Loss: 1.1361\n",
      "Epoch 2/10, Batch 400/1465, Loss: 1.0350\n",
      "Epoch 2/10, Batch 410/1465, Loss: 0.7234\n",
      "Epoch 2/10, Batch 420/1465, Loss: 1.0639\n",
      "Epoch 2/10, Batch 430/1465, Loss: 1.0356\n",
      "Epoch 2/10, Batch 440/1465, Loss: 1.0711\n",
      "Epoch 2/10, Batch 450/1465, Loss: 1.0795\n",
      "Epoch 2/10, Batch 460/1465, Loss: 0.9597\n",
      "Epoch 2/10, Batch 470/1465, Loss: 1.2436\n",
      "Epoch 2/10, Batch 480/1465, Loss: 0.9227\n",
      "Epoch 2/10, Batch 490/1465, Loss: 0.9535\n",
      "Epoch 2/10, Batch 500/1465, Loss: 1.1735\n",
      "Epoch 2/10, Batch 510/1465, Loss: 1.0797\n",
      "Epoch 2/10, Batch 520/1465, Loss: 1.0720\n",
      "Epoch 2/10, Batch 530/1465, Loss: 0.9933\n",
      "Epoch 2/10, Batch 540/1465, Loss: 1.0816\n",
      "Epoch 2/10, Batch 550/1465, Loss: 0.9068\n",
      "Epoch 2/10, Batch 560/1465, Loss: 0.8058\n",
      "Epoch 2/10, Batch 570/1465, Loss: 0.8900\n",
      "Epoch 2/10, Batch 580/1465, Loss: 0.9833\n",
      "Epoch 2/10, Batch 590/1465, Loss: 0.9150\n",
      "Epoch 2/10, Batch 600/1465, Loss: 0.7508\n",
      "Epoch 2/10, Batch 610/1465, Loss: 1.0363\n",
      "Epoch 2/10, Batch 620/1465, Loss: 0.9605\n",
      "Epoch 2/10, Batch 630/1465, Loss: 0.9586\n",
      "Epoch 2/10, Batch 640/1465, Loss: 0.9551\n",
      "Epoch 2/10, Batch 650/1465, Loss: 1.0013\n",
      "Epoch 2/10, Batch 660/1465, Loss: 0.9282\n",
      "Epoch 2/10, Batch 670/1465, Loss: 1.0103\n",
      "Epoch 2/10, Batch 680/1465, Loss: 1.1140\n",
      "Epoch 2/10, Batch 690/1465, Loss: 0.9348\n",
      "Epoch 2/10, Batch 700/1465, Loss: 0.9984\n",
      "Epoch 2/10, Batch 710/1465, Loss: 0.8664\n",
      "Epoch 2/10, Batch 720/1465, Loss: 1.0689\n",
      "Epoch 2/10, Batch 730/1465, Loss: 0.9351\n",
      "Epoch 2/10, Batch 740/1465, Loss: 1.2415\n",
      "Epoch 2/10, Batch 750/1465, Loss: 1.0107\n",
      "Epoch 2/10, Batch 760/1465, Loss: 0.9795\n",
      "Epoch 2/10, Batch 770/1465, Loss: 0.9346\n",
      "Epoch 2/10, Batch 780/1465, Loss: 0.9766\n",
      "Epoch 2/10, Batch 790/1465, Loss: 1.0429\n",
      "Epoch 2/10, Batch 800/1465, Loss: 0.9307\n",
      "Epoch 2/10, Batch 810/1465, Loss: 0.9380\n",
      "Epoch 2/10, Batch 820/1465, Loss: 1.1473\n",
      "Epoch 2/10, Batch 830/1465, Loss: 0.9455\n",
      "Epoch 2/10, Batch 840/1465, Loss: 0.8887\n",
      "Epoch 2/10, Batch 850/1465, Loss: 0.9004\n",
      "Epoch 2/10, Batch 860/1465, Loss: 0.8847\n",
      "Epoch 2/10, Batch 870/1465, Loss: 1.0938\n",
      "Epoch 2/10, Batch 880/1465, Loss: 1.2507\n",
      "Epoch 2/10, Batch 890/1465, Loss: 0.8712\n",
      "Epoch 2/10, Batch 900/1465, Loss: 1.0296\n",
      "Epoch 2/10, Batch 910/1465, Loss: 0.9993\n",
      "Epoch 2/10, Batch 920/1465, Loss: 1.0751\n",
      "Epoch 2/10, Batch 930/1465, Loss: 1.0327\n",
      "Epoch 2/10, Batch 940/1465, Loss: 0.9734\n",
      "Epoch 2/10, Batch 950/1465, Loss: 1.0871\n",
      "Epoch 2/10, Batch 960/1465, Loss: 1.0254\n",
      "Epoch 2/10, Batch 970/1465, Loss: 1.1022\n",
      "Epoch 2/10, Batch 980/1465, Loss: 1.1774\n",
      "Epoch 2/10, Batch 990/1465, Loss: 0.8704\n",
      "Epoch 2/10, Batch 1000/1465, Loss: 0.8910\n",
      "Epoch 2/10, Batch 1010/1465, Loss: 1.0146\n",
      "Epoch 2/10, Batch 1020/1465, Loss: 1.0621\n",
      "Epoch 2/10, Batch 1030/1465, Loss: 1.1141\n",
      "Epoch 2/10, Batch 1040/1465, Loss: 1.1077\n",
      "Epoch 2/10, Batch 1050/1465, Loss: 0.9763\n",
      "Epoch 2/10, Batch 1060/1465, Loss: 0.9446\n",
      "Epoch 2/10, Batch 1070/1465, Loss: 1.1424\n",
      "Epoch 2/10, Batch 1080/1465, Loss: 0.9199\n",
      "Epoch 2/10, Batch 1090/1465, Loss: 0.9021\n",
      "Epoch 2/10, Batch 1100/1465, Loss: 0.8514\n",
      "Epoch 2/10, Batch 1110/1465, Loss: 0.8339\n",
      "Epoch 2/10, Batch 1120/1465, Loss: 1.0351\n",
      "Epoch 2/10, Batch 1130/1465, Loss: 0.8420\n",
      "Epoch 2/10, Batch 1140/1465, Loss: 1.1918\n",
      "Epoch 2/10, Batch 1150/1465, Loss: 0.8637\n",
      "Epoch 2/10, Batch 1160/1465, Loss: 1.0561\n",
      "Epoch 2/10, Batch 1170/1465, Loss: 1.1763\n",
      "Epoch 2/10, Batch 1180/1465, Loss: 1.0464\n",
      "Epoch 2/10, Batch 1190/1465, Loss: 0.8597\n",
      "Epoch 2/10, Batch 1200/1465, Loss: 1.1218\n",
      "Epoch 2/10, Batch 1210/1465, Loss: 0.9029\n",
      "Epoch 2/10, Batch 1220/1465, Loss: 0.8810\n",
      "Epoch 2/10, Batch 1230/1465, Loss: 0.8214\n",
      "Epoch 2/10, Batch 1240/1465, Loss: 0.9653\n",
      "Epoch 2/10, Batch 1250/1465, Loss: 0.9955\n",
      "Epoch 2/10, Batch 1260/1465, Loss: 1.1074\n",
      "Epoch 2/10, Batch 1270/1465, Loss: 1.0093\n",
      "Epoch 2/10, Batch 1280/1465, Loss: 0.8729\n",
      "Epoch 2/10, Batch 1290/1465, Loss: 1.0570\n",
      "Epoch 2/10, Batch 1300/1465, Loss: 1.1517\n",
      "Epoch 2/10, Batch 1310/1465, Loss: 1.0416\n",
      "Epoch 2/10, Batch 1320/1465, Loss: 1.0132\n",
      "Epoch 2/10, Batch 1330/1465, Loss: 0.9356\n",
      "Epoch 2/10, Batch 1340/1465, Loss: 0.8607\n",
      "Epoch 2/10, Batch 1350/1465, Loss: 0.9166\n",
      "Epoch 2/10, Batch 1360/1465, Loss: 1.1092\n",
      "Epoch 2/10, Batch 1370/1465, Loss: 0.8633\n",
      "Epoch 2/10, Batch 1380/1465, Loss: 1.1079\n",
      "Epoch 2/10, Batch 1390/1465, Loss: 1.0132\n",
      "Epoch 2/10, Batch 1400/1465, Loss: 0.9549\n",
      "Epoch 2/10, Batch 1410/1465, Loss: 0.8623\n",
      "Epoch 2/10, Batch 1420/1465, Loss: 1.0426\n",
      "Epoch 2/10, Batch 1430/1465, Loss: 0.9339\n",
      "Epoch 2/10, Batch 1440/1465, Loss: 0.9763\n",
      "Epoch 2/10, Batch 1450/1465, Loss: 0.8270\n",
      "Epoch 2/10, Batch 1460/1465, Loss: 0.9302\n",
      "Epoch [2/10], Average Loss: 0.9867\n",
      "Epoch 3/10, Batch 10/1465, Loss: 0.8730\n",
      "Epoch 3/10, Batch 20/1465, Loss: 1.0706\n",
      "Epoch 3/10, Batch 30/1465, Loss: 0.8998\n",
      "Epoch 3/10, Batch 40/1465, Loss: 0.9363\n",
      "Epoch 3/10, Batch 50/1465, Loss: 0.8341\n",
      "Epoch 3/10, Batch 60/1465, Loss: 0.8039\n",
      "Epoch 3/10, Batch 70/1465, Loss: 0.9153\n",
      "Epoch 3/10, Batch 80/1465, Loss: 0.8564\n",
      "Epoch 3/10, Batch 90/1465, Loss: 1.0464\n",
      "Epoch 3/10, Batch 100/1465, Loss: 0.8772\n",
      "Epoch 3/10, Batch 110/1465, Loss: 0.8693\n",
      "Epoch 3/10, Batch 120/1465, Loss: 1.2860\n",
      "Epoch 3/10, Batch 130/1465, Loss: 0.8319\n",
      "Epoch 3/10, Batch 140/1465, Loss: 1.0761\n",
      "Epoch 3/10, Batch 150/1465, Loss: 0.8906\n",
      "Epoch 3/10, Batch 160/1465, Loss: 0.7341\n",
      "Epoch 3/10, Batch 170/1465, Loss: 0.8173\n",
      "Epoch 3/10, Batch 180/1465, Loss: 0.8286\n",
      "Epoch 3/10, Batch 190/1465, Loss: 0.7753\n",
      "Epoch 3/10, Batch 200/1465, Loss: 0.9008\n",
      "Epoch 3/10, Batch 210/1465, Loss: 1.0675\n",
      "Epoch 3/10, Batch 220/1465, Loss: 1.2064\n",
      "Epoch 3/10, Batch 230/1465, Loss: 0.8248\n",
      "Epoch 3/10, Batch 240/1465, Loss: 1.1845\n",
      "Epoch 3/10, Batch 250/1465, Loss: 0.8193\n",
      "Epoch 3/10, Batch 260/1465, Loss: 0.9320\n",
      "Epoch 3/10, Batch 270/1465, Loss: 0.8638\n",
      "Epoch 3/10, Batch 280/1465, Loss: 0.9668\n",
      "Epoch 3/10, Batch 290/1465, Loss: 0.9762\n",
      "Epoch 3/10, Batch 300/1465, Loss: 0.7868\n",
      "Epoch 3/10, Batch 310/1465, Loss: 1.1101\n",
      "Epoch 3/10, Batch 320/1465, Loss: 0.9249\n",
      "Epoch 3/10, Batch 330/1465, Loss: 0.8751\n",
      "Epoch 3/10, Batch 340/1465, Loss: 1.0268\n",
      "Epoch 3/10, Batch 350/1465, Loss: 0.9407\n",
      "Epoch 3/10, Batch 360/1465, Loss: 0.8873\n",
      "Epoch 3/10, Batch 370/1465, Loss: 1.0475\n",
      "Epoch 3/10, Batch 380/1465, Loss: 0.8254\n",
      "Epoch 3/10, Batch 390/1465, Loss: 0.8413\n",
      "Epoch 3/10, Batch 400/1465, Loss: 0.8783\n",
      "Epoch 3/10, Batch 410/1465, Loss: 1.1166\n",
      "Epoch 3/10, Batch 420/1465, Loss: 0.7045\n",
      "Epoch 3/10, Batch 430/1465, Loss: 0.8341\n",
      "Epoch 3/10, Batch 440/1465, Loss: 0.9267\n",
      "Epoch 3/10, Batch 450/1465, Loss: 0.8231\n",
      "Epoch 3/10, Batch 460/1465, Loss: 1.0487\n",
      "Epoch 3/10, Batch 470/1465, Loss: 0.8458\n",
      "Epoch 3/10, Batch 480/1465, Loss: 0.7789\n",
      "Epoch 3/10, Batch 490/1465, Loss: 0.8930\n",
      "Epoch 3/10, Batch 500/1465, Loss: 0.8877\n",
      "Epoch 3/10, Batch 510/1465, Loss: 0.8416\n",
      "Epoch 3/10, Batch 520/1465, Loss: 1.1369\n",
      "Epoch 3/10, Batch 530/1465, Loss: 1.0621\n",
      "Epoch 3/10, Batch 540/1465, Loss: 1.0878\n",
      "Epoch 3/10, Batch 550/1465, Loss: 1.1046\n",
      "Epoch 3/10, Batch 560/1465, Loss: 0.7712\n",
      "Epoch 3/10, Batch 570/1465, Loss: 0.9999\n",
      "Epoch 3/10, Batch 580/1465, Loss: 0.9048\n",
      "Epoch 3/10, Batch 590/1465, Loss: 0.8766\n",
      "Epoch 3/10, Batch 600/1465, Loss: 0.9152\n",
      "Epoch 3/10, Batch 610/1465, Loss: 0.8795\n",
      "Epoch 3/10, Batch 620/1465, Loss: 0.9846\n",
      "Epoch 3/10, Batch 630/1465, Loss: 1.0107\n",
      "Epoch 3/10, Batch 640/1465, Loss: 1.0138\n",
      "Epoch 3/10, Batch 650/1465, Loss: 0.8793\n",
      "Epoch 3/10, Batch 660/1465, Loss: 0.8480\n",
      "Epoch 3/10, Batch 670/1465, Loss: 0.9202\n",
      "Epoch 3/10, Batch 680/1465, Loss: 1.0689\n",
      "Epoch 3/10, Batch 690/1465, Loss: 0.9674\n",
      "Epoch 3/10, Batch 700/1465, Loss: 0.8731\n",
      "Epoch 3/10, Batch 710/1465, Loss: 0.9876\n",
      "Epoch 3/10, Batch 720/1465, Loss: 0.7970\n",
      "Epoch 3/10, Batch 730/1465, Loss: 0.8729\n",
      "Epoch 3/10, Batch 740/1465, Loss: 0.9157\n",
      "Epoch 3/10, Batch 750/1465, Loss: 1.0396\n",
      "Epoch 3/10, Batch 760/1465, Loss: 0.8744\n",
      "Epoch 3/10, Batch 770/1465, Loss: 1.1301\n",
      "Epoch 3/10, Batch 780/1465, Loss: 0.8673\n",
      "Epoch 3/10, Batch 790/1465, Loss: 0.8757\n",
      "Epoch 3/10, Batch 800/1465, Loss: 0.9684\n",
      "Epoch 3/10, Batch 810/1465, Loss: 0.7959\n",
      "Epoch 3/10, Batch 820/1465, Loss: 0.8653\n",
      "Epoch 3/10, Batch 830/1465, Loss: 0.9996\n",
      "Epoch 3/10, Batch 840/1465, Loss: 0.9875\n",
      "Epoch 3/10, Batch 850/1465, Loss: 0.9767\n",
      "Epoch 3/10, Batch 860/1465, Loss: 0.8947\n",
      "Epoch 3/10, Batch 870/1465, Loss: 0.9589\n",
      "Epoch 3/10, Batch 880/1465, Loss: 0.8144\n",
      "Epoch 3/10, Batch 890/1465, Loss: 1.0444\n",
      "Epoch 3/10, Batch 900/1465, Loss: 1.0249\n",
      "Epoch 3/10, Batch 910/1465, Loss: 1.0588\n",
      "Epoch 3/10, Batch 920/1465, Loss: 1.0147\n",
      "Epoch 3/10, Batch 930/1465, Loss: 1.1258\n",
      "Epoch 3/10, Batch 940/1465, Loss: 0.8156\n",
      "Epoch 3/10, Batch 950/1465, Loss: 0.9796\n",
      "Epoch 3/10, Batch 960/1465, Loss: 0.7937\n",
      "Epoch 3/10, Batch 970/1465, Loss: 0.7576\n",
      "Epoch 3/10, Batch 980/1465, Loss: 0.8988\n",
      "Epoch 3/10, Batch 990/1465, Loss: 0.9455\n",
      "Epoch 3/10, Batch 1000/1465, Loss: 0.9213\n",
      "Epoch 3/10, Batch 1010/1465, Loss: 0.9954\n",
      "Epoch 3/10, Batch 1020/1465, Loss: 0.9200\n",
      "Epoch 3/10, Batch 1030/1465, Loss: 0.9023\n",
      "Epoch 3/10, Batch 1040/1465, Loss: 0.9943\n",
      "Epoch 3/10, Batch 1050/1465, Loss: 0.9880\n",
      "Epoch 3/10, Batch 1060/1465, Loss: 1.0249\n",
      "Epoch 3/10, Batch 1070/1465, Loss: 1.0642\n",
      "Epoch 3/10, Batch 1080/1465, Loss: 1.0066\n",
      "Epoch 3/10, Batch 1090/1465, Loss: 0.8859\n",
      "Epoch 3/10, Batch 1100/1465, Loss: 1.0926\n",
      "Epoch 3/10, Batch 1110/1465, Loss: 0.9307\n",
      "Epoch 3/10, Batch 1120/1465, Loss: 1.1030\n",
      "Epoch 3/10, Batch 1130/1465, Loss: 1.0397\n",
      "Epoch 3/10, Batch 1140/1465, Loss: 0.9958\n",
      "Epoch 3/10, Batch 1150/1465, Loss: 0.9506\n",
      "Epoch 3/10, Batch 1160/1465, Loss: 0.9489\n",
      "Epoch 3/10, Batch 1170/1465, Loss: 0.7776\n",
      "Epoch 3/10, Batch 1180/1465, Loss: 0.8390\n",
      "Epoch 3/10, Batch 1190/1465, Loss: 0.9415\n",
      "Epoch 3/10, Batch 1200/1465, Loss: 0.9509\n",
      "Epoch 3/10, Batch 1210/1465, Loss: 1.0743\n",
      "Epoch 3/10, Batch 1220/1465, Loss: 0.6693\n",
      "Epoch 3/10, Batch 1230/1465, Loss: 0.9815\n",
      "Epoch 3/10, Batch 1240/1465, Loss: 1.0016\n",
      "Epoch 3/10, Batch 1250/1465, Loss: 1.0533\n",
      "Epoch 3/10, Batch 1260/1465, Loss: 1.1539\n",
      "Epoch 3/10, Batch 1270/1465, Loss: 1.0896\n",
      "Epoch 3/10, Batch 1280/1465, Loss: 0.9750\n",
      "Epoch 3/10, Batch 1290/1465, Loss: 0.8616\n",
      "Epoch 3/10, Batch 1300/1465, Loss: 0.7820\n",
      "Epoch 3/10, Batch 1310/1465, Loss: 0.8596\n",
      "Epoch 3/10, Batch 1320/1465, Loss: 0.8363\n",
      "Epoch 3/10, Batch 1330/1465, Loss: 0.9111\n",
      "Epoch 3/10, Batch 1340/1465, Loss: 0.9136\n",
      "Epoch 3/10, Batch 1350/1465, Loss: 1.1397\n",
      "Epoch 3/10, Batch 1360/1465, Loss: 0.9554\n",
      "Epoch 3/10, Batch 1370/1465, Loss: 0.9457\n",
      "Epoch 3/10, Batch 1380/1465, Loss: 1.3369\n",
      "Epoch 3/10, Batch 1390/1465, Loss: 0.9095\n",
      "Epoch 3/10, Batch 1400/1465, Loss: 0.9365\n",
      "Epoch 3/10, Batch 1410/1465, Loss: 0.9566\n",
      "Epoch 3/10, Batch 1420/1465, Loss: 0.7434\n",
      "Epoch 3/10, Batch 1430/1465, Loss: 1.0435\n",
      "Epoch 3/10, Batch 1440/1465, Loss: 1.0321\n",
      "Epoch 3/10, Batch 1450/1465, Loss: 0.7816\n",
      "Epoch 3/10, Batch 1460/1465, Loss: 0.8291\n",
      "Epoch [3/10], Average Loss: 0.9489\n",
      "Epoch 4/10, Batch 10/1465, Loss: 0.9949\n",
      "Epoch 4/10, Batch 20/1465, Loss: 1.0181\n",
      "Epoch 4/10, Batch 30/1465, Loss: 0.8348\n",
      "Epoch 4/10, Batch 40/1465, Loss: 1.0525\n",
      "Epoch 4/10, Batch 50/1465, Loss: 0.8154\n",
      "Epoch 4/10, Batch 60/1465, Loss: 1.0984\n",
      "Epoch 4/10, Batch 70/1465, Loss: 0.9521\n",
      "Epoch 4/10, Batch 80/1465, Loss: 0.8350\n",
      "Epoch 4/10, Batch 90/1465, Loss: 0.8599\n",
      "Epoch 4/10, Batch 100/1465, Loss: 0.6687\n",
      "Epoch 4/10, Batch 110/1465, Loss: 1.1555\n",
      "Epoch 4/10, Batch 120/1465, Loss: 1.0072\n",
      "Epoch 4/10, Batch 130/1465, Loss: 0.7975\n",
      "Epoch 4/10, Batch 140/1465, Loss: 0.9337\n",
      "Epoch 4/10, Batch 150/1465, Loss: 0.9817\n",
      "Epoch 4/10, Batch 160/1465, Loss: 0.8862\n",
      "Epoch 4/10, Batch 170/1465, Loss: 1.0537\n",
      "Epoch 4/10, Batch 180/1465, Loss: 0.8134\n",
      "Epoch 4/10, Batch 190/1465, Loss: 0.9466\n",
      "Epoch 4/10, Batch 200/1465, Loss: 1.0024\n",
      "Epoch 4/10, Batch 210/1465, Loss: 0.8648\n",
      "Epoch 4/10, Batch 220/1465, Loss: 1.1584\n",
      "Epoch 4/10, Batch 230/1465, Loss: 0.9385\n",
      "Epoch 4/10, Batch 240/1465, Loss: 0.9001\n",
      "Epoch 4/10, Batch 250/1465, Loss: 0.9199\n",
      "Epoch 4/10, Batch 260/1465, Loss: 0.8156\n",
      "Epoch 4/10, Batch 270/1465, Loss: 0.9063\n",
      "Epoch 4/10, Batch 280/1465, Loss: 1.0210\n",
      "Epoch 4/10, Batch 290/1465, Loss: 0.9025\n",
      "Epoch 4/10, Batch 300/1465, Loss: 1.1383\n",
      "Epoch 4/10, Batch 310/1465, Loss: 0.9691\n",
      "Epoch 4/10, Batch 320/1465, Loss: 0.8061\n",
      "Epoch 4/10, Batch 330/1465, Loss: 1.0091\n",
      "Epoch 4/10, Batch 340/1465, Loss: 0.8642\n",
      "Epoch 4/10, Batch 350/1465, Loss: 0.7636\n",
      "Epoch 4/10, Batch 360/1465, Loss: 0.9879\n",
      "Epoch 4/10, Batch 370/1465, Loss: 0.9780\n",
      "Epoch 4/10, Batch 380/1465, Loss: 0.9183\n",
      "Epoch 4/10, Batch 390/1465, Loss: 0.9404\n",
      "Epoch 4/10, Batch 400/1465, Loss: 0.8938\n",
      "Epoch 4/10, Batch 410/1465, Loss: 0.8616\n",
      "Epoch 4/10, Batch 420/1465, Loss: 0.6830\n",
      "Epoch 4/10, Batch 430/1465, Loss: 0.9492\n",
      "Epoch 4/10, Batch 440/1465, Loss: 0.9743\n",
      "Epoch 4/10, Batch 450/1465, Loss: 1.0417\n",
      "Epoch 4/10, Batch 460/1465, Loss: 0.8732\n",
      "Epoch 4/10, Batch 470/1465, Loss: 1.1080\n",
      "Epoch 4/10, Batch 480/1465, Loss: 1.0641\n",
      "Epoch 4/10, Batch 490/1465, Loss: 0.9832\n",
      "Epoch 4/10, Batch 500/1465, Loss: 0.8334\n",
      "Epoch 4/10, Batch 510/1465, Loss: 0.8986\n",
      "Epoch 4/10, Batch 520/1465, Loss: 0.9502\n",
      "Epoch 4/10, Batch 530/1465, Loss: 0.8228\n",
      "Epoch 4/10, Batch 540/1465, Loss: 0.8613\n",
      "Epoch 4/10, Batch 550/1465, Loss: 0.9475\n",
      "Epoch 4/10, Batch 560/1465, Loss: 1.1336\n",
      "Epoch 4/10, Batch 570/1465, Loss: 0.8226\n",
      "Epoch 4/10, Batch 580/1465, Loss: 0.8089\n",
      "Epoch 4/10, Batch 590/1465, Loss: 1.0476\n",
      "Epoch 4/10, Batch 600/1465, Loss: 0.9297\n",
      "Epoch 4/10, Batch 610/1465, Loss: 0.7991\n",
      "Epoch 4/10, Batch 620/1465, Loss: 0.9776\n",
      "Epoch 4/10, Batch 630/1465, Loss: 0.9193\n",
      "Epoch 4/10, Batch 640/1465, Loss: 0.9425\n",
      "Epoch 4/10, Batch 650/1465, Loss: 0.8070\n",
      "Epoch 4/10, Batch 660/1465, Loss: 0.9456\n",
      "Epoch 4/10, Batch 670/1465, Loss: 0.9541\n",
      "Epoch 4/10, Batch 680/1465, Loss: 0.8970\n",
      "Epoch 4/10, Batch 690/1465, Loss: 1.1547\n",
      "Epoch 4/10, Batch 700/1465, Loss: 0.7236\n",
      "Epoch 4/10, Batch 710/1465, Loss: 0.8832\n",
      "Epoch 4/10, Batch 720/1465, Loss: 0.9321\n",
      "Epoch 4/10, Batch 730/1465, Loss: 0.9772\n",
      "Epoch 4/10, Batch 740/1465, Loss: 1.3633\n",
      "Epoch 4/10, Batch 750/1465, Loss: 0.8986\n",
      "Epoch 4/10, Batch 760/1465, Loss: 0.6811\n",
      "Epoch 4/10, Batch 770/1465, Loss: 0.8890\n",
      "Epoch 4/10, Batch 780/1465, Loss: 0.7629\n",
      "Epoch 4/10, Batch 790/1465, Loss: 1.0181\n",
      "Epoch 4/10, Batch 800/1465, Loss: 1.0292\n",
      "Epoch 4/10, Batch 810/1465, Loss: 0.9529\n",
      "Epoch 4/10, Batch 820/1465, Loss: 0.9329\n",
      "Epoch 4/10, Batch 830/1465, Loss: 0.8357\n",
      "Epoch 4/10, Batch 840/1465, Loss: 0.7584\n",
      "Epoch 4/10, Batch 850/1465, Loss: 0.9545\n",
      "Epoch 4/10, Batch 860/1465, Loss: 0.8379\n",
      "Epoch 4/10, Batch 870/1465, Loss: 0.8993\n",
      "Epoch 4/10, Batch 880/1465, Loss: 0.7701\n",
      "Epoch 4/10, Batch 890/1465, Loss: 0.9470\n",
      "Epoch 4/10, Batch 900/1465, Loss: 0.8510\n",
      "Epoch 4/10, Batch 910/1465, Loss: 0.8767\n",
      "Epoch 4/10, Batch 920/1465, Loss: 1.0838\n",
      "Epoch 4/10, Batch 930/1465, Loss: 0.8230\n",
      "Epoch 4/10, Batch 940/1465, Loss: 0.8370\n",
      "Epoch 4/10, Batch 950/1465, Loss: 0.9254\n",
      "Epoch 4/10, Batch 960/1465, Loss: 0.8075\n",
      "Epoch 4/10, Batch 970/1465, Loss: 1.0404\n",
      "Epoch 4/10, Batch 980/1465, Loss: 1.0310\n",
      "Epoch 4/10, Batch 990/1465, Loss: 1.1572\n",
      "Epoch 4/10, Batch 1000/1465, Loss: 1.1191\n",
      "Epoch 4/10, Batch 1010/1465, Loss: 0.9324\n",
      "Epoch 4/10, Batch 1020/1465, Loss: 0.6576\n",
      "Epoch 4/10, Batch 1030/1465, Loss: 1.0036\n",
      "Epoch 4/10, Batch 1040/1465, Loss: 0.9198\n",
      "Epoch 4/10, Batch 1050/1465, Loss: 0.8544\n",
      "Epoch 4/10, Batch 1060/1465, Loss: 0.7821\n",
      "Epoch 4/10, Batch 1070/1465, Loss: 0.9559\n",
      "Epoch 4/10, Batch 1080/1465, Loss: 0.9497\n",
      "Epoch 4/10, Batch 1090/1465, Loss: 1.0203\n",
      "Epoch 4/10, Batch 1100/1465, Loss: 1.0072\n",
      "Epoch 4/10, Batch 1110/1465, Loss: 1.0006\n",
      "Epoch 4/10, Batch 1120/1465, Loss: 0.8499\n",
      "Epoch 4/10, Batch 1130/1465, Loss: 0.9098\n",
      "Epoch 4/10, Batch 1140/1465, Loss: 1.0959\n",
      "Epoch 4/10, Batch 1150/1465, Loss: 1.0025\n",
      "Epoch 4/10, Batch 1160/1465, Loss: 0.8885\n",
      "Epoch 4/10, Batch 1170/1465, Loss: 0.8307\n",
      "Epoch 4/10, Batch 1180/1465, Loss: 0.9495\n",
      "Epoch 4/10, Batch 1190/1465, Loss: 1.0479\n",
      "Epoch 4/10, Batch 1200/1465, Loss: 0.9657\n",
      "Epoch 4/10, Batch 1210/1465, Loss: 1.0253\n",
      "Epoch 4/10, Batch 1220/1465, Loss: 0.9236\n",
      "Epoch 4/10, Batch 1230/1465, Loss: 0.9697\n",
      "Epoch 4/10, Batch 1240/1465, Loss: 0.9886\n",
      "Epoch 4/10, Batch 1250/1465, Loss: 0.7675\n",
      "Epoch 4/10, Batch 1260/1465, Loss: 0.7932\n",
      "Epoch 4/10, Batch 1270/1465, Loss: 0.9375\n",
      "Epoch 4/10, Batch 1280/1465, Loss: 0.7600\n",
      "Epoch 4/10, Batch 1290/1465, Loss: 1.0031\n",
      "Epoch 4/10, Batch 1300/1465, Loss: 0.8745\n",
      "Epoch 4/10, Batch 1310/1465, Loss: 0.9295\n",
      "Epoch 4/10, Batch 1320/1465, Loss: 0.8949\n",
      "Epoch 4/10, Batch 1330/1465, Loss: 0.8220\n",
      "Epoch 4/10, Batch 1340/1465, Loss: 0.6902\n",
      "Epoch 4/10, Batch 1350/1465, Loss: 0.9174\n",
      "Epoch 4/10, Batch 1360/1465, Loss: 0.9316\n",
      "Epoch 4/10, Batch 1370/1465, Loss: 1.0748\n",
      "Epoch 4/10, Batch 1380/1465, Loss: 1.0861\n",
      "Epoch 4/10, Batch 1390/1465, Loss: 0.7905\n",
      "Epoch 4/10, Batch 1400/1465, Loss: 1.0048\n",
      "Epoch 4/10, Batch 1410/1465, Loss: 1.0077\n",
      "Epoch 4/10, Batch 1420/1465, Loss: 0.8506\n",
      "Epoch 4/10, Batch 1430/1465, Loss: 1.0580\n",
      "Epoch 4/10, Batch 1440/1465, Loss: 1.0982\n",
      "Epoch 4/10, Batch 1450/1465, Loss: 0.9173\n",
      "Epoch 4/10, Batch 1460/1465, Loss: 0.8632\n",
      "Epoch [4/10], Average Loss: 0.9194\n",
      "Epoch 5/10, Batch 10/1465, Loss: 0.9671\n",
      "Epoch 5/10, Batch 20/1465, Loss: 1.2586\n",
      "Epoch 5/10, Batch 30/1465, Loss: 0.7735\n",
      "Epoch 5/10, Batch 40/1465, Loss: 0.8101\n",
      "Epoch 5/10, Batch 50/1465, Loss: 1.0598\n",
      "Epoch 5/10, Batch 60/1465, Loss: 0.8454\n",
      "Epoch 5/10, Batch 70/1465, Loss: 0.8141\n",
      "Epoch 5/10, Batch 80/1465, Loss: 0.7492\n",
      "Epoch 5/10, Batch 90/1465, Loss: 0.9927\n",
      "Epoch 5/10, Batch 100/1465, Loss: 0.9279\n",
      "Epoch 5/10, Batch 110/1465, Loss: 0.7548\n",
      "Epoch 5/10, Batch 120/1465, Loss: 0.9057\n",
      "Epoch 5/10, Batch 130/1465, Loss: 0.7626\n",
      "Epoch 5/10, Batch 140/1465, Loss: 0.9283\n",
      "Epoch 5/10, Batch 150/1465, Loss: 0.8569\n",
      "Epoch 5/10, Batch 160/1465, Loss: 0.8556\n",
      "Epoch 5/10, Batch 170/1465, Loss: 0.8642\n",
      "Epoch 5/10, Batch 180/1465, Loss: 0.9262\n",
      "Epoch 5/10, Batch 190/1465, Loss: 1.0354\n",
      "Epoch 5/10, Batch 200/1465, Loss: 0.8416\n",
      "Epoch 5/10, Batch 210/1465, Loss: 0.8312\n",
      "Epoch 5/10, Batch 220/1465, Loss: 0.9261\n",
      "Epoch 5/10, Batch 230/1465, Loss: 0.9545\n",
      "Epoch 5/10, Batch 240/1465, Loss: 0.9832\n",
      "Epoch 5/10, Batch 250/1465, Loss: 0.9916\n",
      "Epoch 5/10, Batch 260/1465, Loss: 0.8798\n",
      "Epoch 5/10, Batch 270/1465, Loss: 1.1336\n",
      "Epoch 5/10, Batch 280/1465, Loss: 0.8602\n",
      "Epoch 5/10, Batch 290/1465, Loss: 0.9621\n",
      "Epoch 5/10, Batch 300/1465, Loss: 1.0428\n",
      "Epoch 5/10, Batch 310/1465, Loss: 0.6974\n",
      "Epoch 5/10, Batch 320/1465, Loss: 0.8531\n",
      "Epoch 5/10, Batch 330/1465, Loss: 0.7487\n",
      "Epoch 5/10, Batch 340/1465, Loss: 0.8407\n",
      "Epoch 5/10, Batch 350/1465, Loss: 0.8785\n",
      "Epoch 5/10, Batch 360/1465, Loss: 0.8970\n",
      "Epoch 5/10, Batch 370/1465, Loss: 0.9866\n",
      "Epoch 5/10, Batch 380/1465, Loss: 0.7446\n",
      "Epoch 5/10, Batch 390/1465, Loss: 0.7281\n",
      "Epoch 5/10, Batch 400/1465, Loss: 1.0382\n",
      "Epoch 5/10, Batch 410/1465, Loss: 0.5846\n",
      "Epoch 5/10, Batch 420/1465, Loss: 0.8254\n",
      "Epoch 5/10, Batch 430/1465, Loss: 0.8157\n",
      "Epoch 5/10, Batch 440/1465, Loss: 1.1193\n",
      "Epoch 5/10, Batch 450/1465, Loss: 0.8749\n",
      "Epoch 5/10, Batch 460/1465, Loss: 0.8564\n",
      "Epoch 5/10, Batch 470/1465, Loss: 0.8205\n",
      "Epoch 5/10, Batch 480/1465, Loss: 0.8893\n",
      "Epoch 5/10, Batch 490/1465, Loss: 0.7180\n",
      "Epoch 5/10, Batch 500/1465, Loss: 0.6888\n",
      "Epoch 5/10, Batch 510/1465, Loss: 0.8894\n",
      "Epoch 5/10, Batch 520/1465, Loss: 0.9924\n",
      "Epoch 5/10, Batch 530/1465, Loss: 0.8120\n",
      "Epoch 5/10, Batch 540/1465, Loss: 0.8058\n",
      "Epoch 5/10, Batch 550/1465, Loss: 0.9728\n",
      "Epoch 5/10, Batch 560/1465, Loss: 1.0425\n",
      "Epoch 5/10, Batch 570/1465, Loss: 0.8922\n",
      "Epoch 5/10, Batch 580/1465, Loss: 0.7571\n",
      "Epoch 5/10, Batch 590/1465, Loss: 0.8296\n",
      "Epoch 5/10, Batch 600/1465, Loss: 0.8386\n",
      "Epoch 5/10, Batch 610/1465, Loss: 0.7122\n",
      "Epoch 5/10, Batch 620/1465, Loss: 0.9379\n",
      "Epoch 5/10, Batch 630/1465, Loss: 0.9070\n",
      "Epoch 5/10, Batch 640/1465, Loss: 1.1540\n",
      "Epoch 5/10, Batch 650/1465, Loss: 0.9074\n",
      "Epoch 5/10, Batch 660/1465, Loss: 0.7754\n",
      "Epoch 5/10, Batch 670/1465, Loss: 0.9922\n",
      "Epoch 5/10, Batch 680/1465, Loss: 0.9635\n",
      "Epoch 5/10, Batch 690/1465, Loss: 0.8646\n",
      "Epoch 5/10, Batch 700/1465, Loss: 0.8509\n",
      "Epoch 5/10, Batch 710/1465, Loss: 0.9463\n",
      "Epoch 5/10, Batch 720/1465, Loss: 0.9158\n",
      "Epoch 5/10, Batch 730/1465, Loss: 0.9239\n",
      "Epoch 5/10, Batch 740/1465, Loss: 0.8057\n",
      "Epoch 5/10, Batch 750/1465, Loss: 0.8036\n",
      "Epoch 5/10, Batch 760/1465, Loss: 0.7882\n",
      "Epoch 5/10, Batch 770/1465, Loss: 0.8374\n",
      "Epoch 5/10, Batch 780/1465, Loss: 1.0042\n",
      "Epoch 5/10, Batch 790/1465, Loss: 1.1343\n",
      "Epoch 5/10, Batch 800/1465, Loss: 0.8062\n",
      "Epoch 5/10, Batch 810/1465, Loss: 1.0060\n",
      "Epoch 5/10, Batch 820/1465, Loss: 1.0532\n",
      "Epoch 5/10, Batch 830/1465, Loss: 1.0018\n",
      "Epoch 5/10, Batch 840/1465, Loss: 0.8125\n",
      "Epoch 5/10, Batch 850/1465, Loss: 0.8073\n",
      "Epoch 5/10, Batch 860/1465, Loss: 0.8542\n",
      "Epoch 5/10, Batch 870/1465, Loss: 0.9983\n",
      "Epoch 5/10, Batch 880/1465, Loss: 0.8176\n",
      "Epoch 5/10, Batch 890/1465, Loss: 1.0691\n",
      "Epoch 5/10, Batch 900/1465, Loss: 0.8494\n",
      "Epoch 5/10, Batch 910/1465, Loss: 0.7796\n",
      "Epoch 5/10, Batch 920/1465, Loss: 1.0263\n",
      "Epoch 5/10, Batch 930/1465, Loss: 1.0059\n",
      "Epoch 5/10, Batch 940/1465, Loss: 0.6964\n",
      "Epoch 5/10, Batch 950/1465, Loss: 0.9577\n",
      "Epoch 5/10, Batch 960/1465, Loss: 0.7228\n",
      "Epoch 5/10, Batch 970/1465, Loss: 0.7411\n",
      "Epoch 5/10, Batch 980/1465, Loss: 0.8936\n",
      "Epoch 5/10, Batch 990/1465, Loss: 1.0495\n",
      "Epoch 5/10, Batch 1000/1465, Loss: 1.0598\n",
      "Epoch 5/10, Batch 1010/1465, Loss: 0.9964\n",
      "Epoch 5/10, Batch 1020/1465, Loss: 0.9426\n",
      "Epoch 5/10, Batch 1030/1465, Loss: 1.0704\n",
      "Epoch 5/10, Batch 1040/1465, Loss: 0.8769\n",
      "Epoch 5/10, Batch 1050/1465, Loss: 0.8458\n",
      "Epoch 5/10, Batch 1060/1465, Loss: 0.8914\n",
      "Epoch 5/10, Batch 1070/1465, Loss: 0.9515\n",
      "Epoch 5/10, Batch 1080/1465, Loss: 1.0672\n",
      "Epoch 5/10, Batch 1090/1465, Loss: 1.0975\n",
      "Epoch 5/10, Batch 1100/1465, Loss: 0.7450\n",
      "Epoch 5/10, Batch 1110/1465, Loss: 0.8178\n",
      "Epoch 5/10, Batch 1120/1465, Loss: 0.8021\n",
      "Epoch 5/10, Batch 1130/1465, Loss: 1.0055\n",
      "Epoch 5/10, Batch 1140/1465, Loss: 0.6943\n",
      "Epoch 5/10, Batch 1150/1465, Loss: 0.8678\n",
      "Epoch 5/10, Batch 1160/1465, Loss: 0.8399\n",
      "Epoch 5/10, Batch 1170/1465, Loss: 0.8364\n",
      "Epoch 5/10, Batch 1180/1465, Loss: 0.8882\n",
      "Epoch 5/10, Batch 1190/1465, Loss: 0.9947\n",
      "Epoch 5/10, Batch 1200/1465, Loss: 0.9567\n",
      "Epoch 5/10, Batch 1210/1465, Loss: 0.9171\n",
      "Epoch 5/10, Batch 1220/1465, Loss: 0.8673\n",
      "Epoch 5/10, Batch 1230/1465, Loss: 0.9914\n",
      "Epoch 5/10, Batch 1240/1465, Loss: 1.0506\n",
      "Epoch 5/10, Batch 1250/1465, Loss: 1.1751\n",
      "Epoch 5/10, Batch 1260/1465, Loss: 0.8258\n",
      "Epoch 5/10, Batch 1270/1465, Loss: 1.0582\n",
      "Epoch 5/10, Batch 1280/1465, Loss: 0.8509\n",
      "Epoch 5/10, Batch 1290/1465, Loss: 0.7661\n",
      "Epoch 5/10, Batch 1300/1465, Loss: 1.0314\n",
      "Epoch 5/10, Batch 1310/1465, Loss: 0.9245\n",
      "Epoch 5/10, Batch 1320/1465, Loss: 0.7238\n",
      "Epoch 5/10, Batch 1330/1465, Loss: 0.9591\n",
      "Epoch 5/10, Batch 1340/1465, Loss: 0.8204\n",
      "Epoch 5/10, Batch 1350/1465, Loss: 0.9430\n",
      "Epoch 5/10, Batch 1360/1465, Loss: 0.8963\n",
      "Epoch 5/10, Batch 1370/1465, Loss: 0.9544\n",
      "Epoch 5/10, Batch 1380/1465, Loss: 0.8509\n",
      "Epoch 5/10, Batch 1390/1465, Loss: 1.0617\n",
      "Epoch 5/10, Batch 1400/1465, Loss: 0.8790\n",
      "Epoch 5/10, Batch 1410/1465, Loss: 0.8203\n",
      "Epoch 5/10, Batch 1420/1465, Loss: 0.8821\n",
      "Epoch 5/10, Batch 1430/1465, Loss: 0.9479\n",
      "Epoch 5/10, Batch 1440/1465, Loss: 1.0735\n",
      "Epoch 5/10, Batch 1450/1465, Loss: 0.9899\n",
      "Epoch 5/10, Batch 1460/1465, Loss: 0.7187\n",
      "Epoch [5/10], Average Loss: 0.9028\n",
      "Epoch 6/10, Batch 10/1465, Loss: 0.9044\n",
      "Epoch 6/10, Batch 20/1465, Loss: 0.7500\n",
      "Epoch 6/10, Batch 30/1465, Loss: 0.8559\n",
      "Epoch 6/10, Batch 40/1465, Loss: 0.8644\n",
      "Epoch 6/10, Batch 50/1465, Loss: 0.9584\n",
      "Epoch 6/10, Batch 60/1465, Loss: 0.6932\n",
      "Epoch 6/10, Batch 70/1465, Loss: 0.8842\n",
      "Epoch 6/10, Batch 80/1465, Loss: 0.9711\n",
      "Epoch 6/10, Batch 90/1465, Loss: 0.7965\n",
      "Epoch 6/10, Batch 100/1465, Loss: 0.8621\n",
      "Epoch 6/10, Batch 110/1465, Loss: 0.8838\n",
      "Epoch 6/10, Batch 120/1465, Loss: 0.7396\n",
      "Epoch 6/10, Batch 130/1465, Loss: 0.8191\n",
      "Epoch 6/10, Batch 140/1465, Loss: 0.8093\n",
      "Epoch 6/10, Batch 150/1465, Loss: 0.8877\n",
      "Epoch 6/10, Batch 160/1465, Loss: 0.8628\n",
      "Epoch 6/10, Batch 170/1465, Loss: 0.9921\n",
      "Epoch 6/10, Batch 180/1465, Loss: 0.7484\n",
      "Epoch 6/10, Batch 190/1465, Loss: 0.6357\n",
      "Epoch 6/10, Batch 200/1465, Loss: 0.6277\n",
      "Epoch 6/10, Batch 210/1465, Loss: 0.9168\n",
      "Epoch 6/10, Batch 220/1465, Loss: 0.7752\n",
      "Epoch 6/10, Batch 230/1465, Loss: 0.7536\n",
      "Epoch 6/10, Batch 240/1465, Loss: 0.6649\n",
      "Epoch 6/10, Batch 250/1465, Loss: 1.0873\n",
      "Epoch 6/10, Batch 260/1465, Loss: 0.7721\n",
      "Epoch 6/10, Batch 270/1465, Loss: 0.7825\n",
      "Epoch 6/10, Batch 280/1465, Loss: 0.8366\n",
      "Epoch 6/10, Batch 290/1465, Loss: 0.9600\n",
      "Epoch 6/10, Batch 300/1465, Loss: 1.0599\n",
      "Epoch 6/10, Batch 310/1465, Loss: 0.7711\n",
      "Epoch 6/10, Batch 320/1465, Loss: 0.7330\n",
      "Epoch 6/10, Batch 330/1465, Loss: 0.6685\n",
      "Epoch 6/10, Batch 340/1465, Loss: 1.0106\n",
      "Epoch 6/10, Batch 350/1465, Loss: 1.1829\n",
      "Epoch 6/10, Batch 360/1465, Loss: 0.9957\n",
      "Epoch 6/10, Batch 370/1465, Loss: 1.3269\n",
      "Epoch 6/10, Batch 380/1465, Loss: 1.0561\n",
      "Epoch 6/10, Batch 390/1465, Loss: 0.8635\n",
      "Epoch 6/10, Batch 400/1465, Loss: 0.8044\n",
      "Epoch 6/10, Batch 410/1465, Loss: 0.8146\n",
      "Epoch 6/10, Batch 420/1465, Loss: 0.7412\n",
      "Epoch 6/10, Batch 430/1465, Loss: 0.7813\n",
      "Epoch 6/10, Batch 440/1465, Loss: 0.9281\n",
      "Epoch 6/10, Batch 450/1465, Loss: 0.9417\n",
      "Epoch 6/10, Batch 460/1465, Loss: 0.8827\n",
      "Epoch 6/10, Batch 470/1465, Loss: 0.9873\n",
      "Epoch 6/10, Batch 480/1465, Loss: 0.8616\n",
      "Epoch 6/10, Batch 490/1465, Loss: 1.0993\n",
      "Epoch 6/10, Batch 500/1465, Loss: 0.8660\n",
      "Epoch 6/10, Batch 510/1465, Loss: 0.6734\n",
      "Epoch 6/10, Batch 520/1465, Loss: 0.7884\n",
      "Epoch 6/10, Batch 530/1465, Loss: 0.8711\n",
      "Epoch 6/10, Batch 540/1465, Loss: 0.8056\n",
      "Epoch 6/10, Batch 550/1465, Loss: 0.7113\n",
      "Epoch 6/10, Batch 560/1465, Loss: 1.0891\n",
      "Epoch 6/10, Batch 570/1465, Loss: 0.6851\n",
      "Epoch 6/10, Batch 580/1465, Loss: 0.6425\n",
      "Epoch 6/10, Batch 590/1465, Loss: 0.6828\n",
      "Epoch 6/10, Batch 600/1465, Loss: 1.0834\n",
      "Epoch 6/10, Batch 610/1465, Loss: 0.9345\n",
      "Epoch 6/10, Batch 620/1465, Loss: 0.8747\n",
      "Epoch 6/10, Batch 630/1465, Loss: 1.0109\n",
      "Epoch 6/10, Batch 640/1465, Loss: 0.8455\n",
      "Epoch 6/10, Batch 650/1465, Loss: 0.8458\n",
      "Epoch 6/10, Batch 660/1465, Loss: 0.8120\n",
      "Epoch 6/10, Batch 670/1465, Loss: 0.8601\n",
      "Epoch 6/10, Batch 680/1465, Loss: 0.6203\n",
      "Epoch 6/10, Batch 690/1465, Loss: 0.6237\n",
      "Epoch 6/10, Batch 700/1465, Loss: 0.9564\n",
      "Epoch 6/10, Batch 710/1465, Loss: 0.7346\n",
      "Epoch 6/10, Batch 720/1465, Loss: 0.8415\n",
      "Epoch 6/10, Batch 730/1465, Loss: 0.8367\n",
      "Epoch 6/10, Batch 740/1465, Loss: 0.9245\n",
      "Epoch 6/10, Batch 750/1465, Loss: 0.7878\n",
      "Epoch 6/10, Batch 760/1465, Loss: 0.7434\n",
      "Epoch 6/10, Batch 770/1465, Loss: 0.8978\n",
      "Epoch 6/10, Batch 780/1465, Loss: 0.9657\n",
      "Epoch 6/10, Batch 790/1465, Loss: 1.0526\n",
      "Epoch 6/10, Batch 800/1465, Loss: 0.9263\n",
      "Epoch 6/10, Batch 810/1465, Loss: 1.0662\n",
      "Epoch 6/10, Batch 820/1465, Loss: 1.0261\n",
      "Epoch 6/10, Batch 830/1465, Loss: 0.8600\n",
      "Epoch 6/10, Batch 840/1465, Loss: 0.7781\n",
      "Epoch 6/10, Batch 850/1465, Loss: 0.8048\n",
      "Epoch 6/10, Batch 860/1465, Loss: 0.8459\n",
      "Epoch 6/10, Batch 870/1465, Loss: 1.1734\n",
      "Epoch 6/10, Batch 880/1465, Loss: 1.0444\n",
      "Epoch 6/10, Batch 890/1465, Loss: 0.8740\n",
      "Epoch 6/10, Batch 900/1465, Loss: 0.8938\n",
      "Epoch 6/10, Batch 910/1465, Loss: 0.7843\n",
      "Epoch 6/10, Batch 920/1465, Loss: 0.8066\n",
      "Epoch 6/10, Batch 930/1465, Loss: 0.9474\n",
      "Epoch 6/10, Batch 940/1465, Loss: 0.7758\n",
      "Epoch 6/10, Batch 950/1465, Loss: 0.9055\n",
      "Epoch 6/10, Batch 960/1465, Loss: 1.1086\n",
      "Epoch 6/10, Batch 970/1465, Loss: 0.6894\n",
      "Epoch 6/10, Batch 980/1465, Loss: 0.9563\n",
      "Epoch 6/10, Batch 990/1465, Loss: 0.8809\n",
      "Epoch 6/10, Batch 1000/1465, Loss: 0.7457\n",
      "Epoch 6/10, Batch 1010/1465, Loss: 0.9144\n",
      "Epoch 6/10, Batch 1020/1465, Loss: 0.9439\n",
      "Epoch 6/10, Batch 1030/1465, Loss: 0.8190\n",
      "Epoch 6/10, Batch 1040/1465, Loss: 0.8725\n",
      "Epoch 6/10, Batch 1050/1465, Loss: 0.9386\n",
      "Epoch 6/10, Batch 1060/1465, Loss: 1.0800\n",
      "Epoch 6/10, Batch 1070/1465, Loss: 0.9941\n",
      "Epoch 6/10, Batch 1080/1465, Loss: 0.8704\n",
      "Epoch 6/10, Batch 1090/1465, Loss: 0.9222\n",
      "Epoch 6/10, Batch 1100/1465, Loss: 1.0455\n",
      "Epoch 6/10, Batch 1110/1465, Loss: 0.8831\n",
      "Epoch 6/10, Batch 1120/1465, Loss: 1.0528\n",
      "Epoch 6/10, Batch 1130/1465, Loss: 0.9050\n",
      "Epoch 6/10, Batch 1140/1465, Loss: 0.8369\n",
      "Epoch 6/10, Batch 1150/1465, Loss: 0.7684\n",
      "Epoch 6/10, Batch 1160/1465, Loss: 1.0613\n",
      "Epoch 6/10, Batch 1170/1465, Loss: 0.8321\n",
      "Epoch 6/10, Batch 1180/1465, Loss: 0.8150\n",
      "Epoch 6/10, Batch 1190/1465, Loss: 0.8997\n",
      "Epoch 6/10, Batch 1200/1465, Loss: 0.9928\n",
      "Epoch 6/10, Batch 1210/1465, Loss: 0.9862\n",
      "Epoch 6/10, Batch 1220/1465, Loss: 0.9962\n",
      "Epoch 6/10, Batch 1230/1465, Loss: 0.9409\n",
      "Epoch 6/10, Batch 1240/1465, Loss: 0.7890\n",
      "Epoch 6/10, Batch 1250/1465, Loss: 0.8378\n",
      "Epoch 6/10, Batch 1260/1465, Loss: 0.8693\n",
      "Epoch 6/10, Batch 1270/1465, Loss: 0.8619\n",
      "Epoch 6/10, Batch 1280/1465, Loss: 0.8139\n",
      "Epoch 6/10, Batch 1290/1465, Loss: 0.9441\n",
      "Epoch 6/10, Batch 1300/1465, Loss: 0.8311\n",
      "Epoch 6/10, Batch 1310/1465, Loss: 0.9490\n",
      "Epoch 6/10, Batch 1320/1465, Loss: 0.8368\n",
      "Epoch 6/10, Batch 1330/1465, Loss: 0.9294\n",
      "Epoch 6/10, Batch 1340/1465, Loss: 0.8021\n",
      "Epoch 6/10, Batch 1350/1465, Loss: 0.7949\n",
      "Epoch 6/10, Batch 1360/1465, Loss: 0.8764\n",
      "Epoch 6/10, Batch 1370/1465, Loss: 0.8687\n",
      "Epoch 6/10, Batch 1380/1465, Loss: 0.7404\n",
      "Epoch 6/10, Batch 1390/1465, Loss: 0.9181\n",
      "Epoch 6/10, Batch 1400/1465, Loss: 0.9724\n",
      "Epoch 6/10, Batch 1410/1465, Loss: 1.0613\n",
      "Epoch 6/10, Batch 1420/1465, Loss: 0.8548\n",
      "Epoch 6/10, Batch 1430/1465, Loss: 0.6778\n",
      "Epoch 6/10, Batch 1440/1465, Loss: 0.7206\n",
      "Epoch 6/10, Batch 1450/1465, Loss: 0.9264\n",
      "Epoch 6/10, Batch 1460/1465, Loss: 0.8288\n",
      "Epoch [6/10], Average Loss: 0.8860\n",
      "Epoch 7/10, Batch 10/1465, Loss: 1.0286\n",
      "Epoch 7/10, Batch 20/1465, Loss: 0.7428\n",
      "Epoch 7/10, Batch 30/1465, Loss: 1.1518\n",
      "Epoch 7/10, Batch 40/1465, Loss: 0.7951\n",
      "Epoch 7/10, Batch 50/1465, Loss: 0.8062\n",
      "Epoch 7/10, Batch 60/1465, Loss: 0.6440\n",
      "Epoch 7/10, Batch 70/1465, Loss: 0.8951\n",
      "Epoch 7/10, Batch 80/1465, Loss: 1.0125\n",
      "Epoch 7/10, Batch 90/1465, Loss: 0.9834\n",
      "Epoch 7/10, Batch 100/1465, Loss: 0.8514\n",
      "Epoch 7/10, Batch 110/1465, Loss: 0.8139\n",
      "Epoch 7/10, Batch 120/1465, Loss: 0.9312\n",
      "Epoch 7/10, Batch 130/1465, Loss: 0.8949\n",
      "Epoch 7/10, Batch 140/1465, Loss: 0.8796\n",
      "Epoch 7/10, Batch 150/1465, Loss: 0.8380\n",
      "Epoch 7/10, Batch 160/1465, Loss: 0.7924\n",
      "Epoch 7/10, Batch 170/1465, Loss: 0.9821\n",
      "Epoch 7/10, Batch 180/1465, Loss: 0.9437\n",
      "Epoch 7/10, Batch 190/1465, Loss: 0.9231\n",
      "Epoch 7/10, Batch 200/1465, Loss: 0.7026\n",
      "Epoch 7/10, Batch 210/1465, Loss: 0.9337\n",
      "Epoch 7/10, Batch 220/1465, Loss: 0.9460\n",
      "Epoch 7/10, Batch 230/1465, Loss: 0.9266\n",
      "Epoch 7/10, Batch 240/1465, Loss: 0.7529\n",
      "Epoch 7/10, Batch 250/1465, Loss: 0.9560\n",
      "Epoch 7/10, Batch 260/1465, Loss: 0.9735\n",
      "Epoch 7/10, Batch 270/1465, Loss: 1.0403\n",
      "Epoch 7/10, Batch 280/1465, Loss: 0.7694\n",
      "Epoch 7/10, Batch 290/1465, Loss: 0.9273\n",
      "Epoch 7/10, Batch 300/1465, Loss: 0.7550\n",
      "Epoch 7/10, Batch 310/1465, Loss: 0.9236\n",
      "Epoch 7/10, Batch 320/1465, Loss: 0.8605\n",
      "Epoch 7/10, Batch 330/1465, Loss: 0.6618\n",
      "Epoch 7/10, Batch 340/1465, Loss: 0.8013\n",
      "Epoch 7/10, Batch 350/1465, Loss: 1.1637\n",
      "Epoch 7/10, Batch 360/1465, Loss: 0.6906\n",
      "Epoch 7/10, Batch 370/1465, Loss: 0.8178\n",
      "Epoch 7/10, Batch 380/1465, Loss: 0.7347\n",
      "Epoch 7/10, Batch 390/1465, Loss: 0.8023\n",
      "Epoch 7/10, Batch 400/1465, Loss: 1.0737\n",
      "Epoch 7/10, Batch 410/1465, Loss: 0.7958\n",
      "Epoch 7/10, Batch 420/1465, Loss: 0.8045\n",
      "Epoch 7/10, Batch 430/1465, Loss: 0.6693\n",
      "Epoch 7/10, Batch 440/1465, Loss: 0.8864\n",
      "Epoch 7/10, Batch 450/1465, Loss: 0.9170\n",
      "Epoch 7/10, Batch 460/1465, Loss: 0.7370\n",
      "Epoch 7/10, Batch 470/1465, Loss: 1.0237\n",
      "Epoch 7/10, Batch 480/1465, Loss: 0.8660\n",
      "Epoch 7/10, Batch 490/1465, Loss: 0.9566\n",
      "Epoch 7/10, Batch 500/1465, Loss: 0.7962\n",
      "Epoch 7/10, Batch 510/1465, Loss: 0.9376\n",
      "Epoch 7/10, Batch 520/1465, Loss: 0.8927\n",
      "Epoch 7/10, Batch 530/1465, Loss: 0.8219\n",
      "Epoch 7/10, Batch 540/1465, Loss: 0.7835\n",
      "Epoch 7/10, Batch 550/1465, Loss: 0.7952\n",
      "Epoch 7/10, Batch 560/1465, Loss: 1.0377\n",
      "Epoch 7/10, Batch 570/1465, Loss: 0.8622\n",
      "Epoch 7/10, Batch 580/1465, Loss: 0.9883\n",
      "Epoch 7/10, Batch 590/1465, Loss: 0.8175\n",
      "Epoch 7/10, Batch 600/1465, Loss: 0.9922\n",
      "Epoch 7/10, Batch 610/1465, Loss: 0.9350\n",
      "Epoch 7/10, Batch 620/1465, Loss: 0.9200\n",
      "Epoch 7/10, Batch 630/1465, Loss: 0.8372\n",
      "Epoch 7/10, Batch 640/1465, Loss: 0.9723\n",
      "Epoch 7/10, Batch 650/1465, Loss: 0.8377\n",
      "Epoch 7/10, Batch 660/1465, Loss: 1.0747\n",
      "Epoch 7/10, Batch 670/1465, Loss: 0.7923\n",
      "Epoch 7/10, Batch 680/1465, Loss: 1.1180\n",
      "Epoch 7/10, Batch 690/1465, Loss: 0.8579\n",
      "Epoch 7/10, Batch 700/1465, Loss: 0.8101\n",
      "Epoch 7/10, Batch 710/1465, Loss: 0.8764\n",
      "Epoch 7/10, Batch 720/1465, Loss: 1.1576\n",
      "Epoch 7/10, Batch 730/1465, Loss: 0.9792\n",
      "Epoch 7/10, Batch 740/1465, Loss: 1.0022\n",
      "Epoch 7/10, Batch 750/1465, Loss: 1.1182\n",
      "Epoch 7/10, Batch 760/1465, Loss: 0.7781\n",
      "Epoch 7/10, Batch 770/1465, Loss: 1.0460\n",
      "Epoch 7/10, Batch 780/1465, Loss: 0.8973\n",
      "Epoch 7/10, Batch 790/1465, Loss: 0.7987\n",
      "Epoch 7/10, Batch 800/1465, Loss: 0.9331\n",
      "Epoch 7/10, Batch 810/1465, Loss: 1.0843\n",
      "Epoch 7/10, Batch 820/1465, Loss: 0.9465\n",
      "Epoch 7/10, Batch 830/1465, Loss: 0.6939\n",
      "Epoch 7/10, Batch 840/1465, Loss: 0.7952\n",
      "Epoch 7/10, Batch 850/1465, Loss: 0.7177\n",
      "Epoch 7/10, Batch 860/1465, Loss: 0.9379\n",
      "Epoch 7/10, Batch 870/1465, Loss: 0.8986\n",
      "Epoch 7/10, Batch 880/1465, Loss: 0.7082\n",
      "Epoch 7/10, Batch 890/1465, Loss: 0.9777\n",
      "Epoch 7/10, Batch 900/1465, Loss: 1.1498\n",
      "Epoch 7/10, Batch 910/1465, Loss: 0.7448\n",
      "Epoch 7/10, Batch 920/1465, Loss: 0.7325\n",
      "Epoch 7/10, Batch 930/1465, Loss: 0.6181\n",
      "Epoch 7/10, Batch 940/1465, Loss: 0.9280\n",
      "Epoch 7/10, Batch 950/1465, Loss: 0.7233\n",
      "Epoch 7/10, Batch 960/1465, Loss: 0.7997\n",
      "Epoch 7/10, Batch 970/1465, Loss: 0.8336\n",
      "Epoch 7/10, Batch 980/1465, Loss: 0.9887\n",
      "Epoch 7/10, Batch 990/1465, Loss: 1.0637\n",
      "Epoch 7/10, Batch 1000/1465, Loss: 0.7696\n",
      "Epoch 7/10, Batch 1010/1465, Loss: 0.7709\n",
      "Epoch 7/10, Batch 1020/1465, Loss: 0.9818\n",
      "Epoch 7/10, Batch 1030/1465, Loss: 0.8825\n",
      "Epoch 7/10, Batch 1040/1465, Loss: 0.7625\n",
      "Epoch 7/10, Batch 1050/1465, Loss: 0.9265\n",
      "Epoch 7/10, Batch 1060/1465, Loss: 0.8624\n",
      "Epoch 7/10, Batch 1070/1465, Loss: 0.7549\n",
      "Epoch 7/10, Batch 1080/1465, Loss: 0.9045\n",
      "Epoch 7/10, Batch 1090/1465, Loss: 0.8022\n",
      "Epoch 7/10, Batch 1100/1465, Loss: 0.6711\n",
      "Epoch 7/10, Batch 1110/1465, Loss: 0.7992\n",
      "Epoch 7/10, Batch 1120/1465, Loss: 0.9670\n",
      "Epoch 7/10, Batch 1130/1465, Loss: 0.7534\n",
      "Epoch 7/10, Batch 1140/1465, Loss: 0.7240\n",
      "Epoch 7/10, Batch 1150/1465, Loss: 0.9036\n",
      "Epoch 7/10, Batch 1160/1465, Loss: 0.9651\n",
      "Epoch 7/10, Batch 1170/1465, Loss: 0.8117\n",
      "Epoch 7/10, Batch 1180/1465, Loss: 0.9063\n",
      "Epoch 7/10, Batch 1190/1465, Loss: 1.0473\n",
      "Epoch 7/10, Batch 1200/1465, Loss: 0.9397\n",
      "Epoch 7/10, Batch 1210/1465, Loss: 0.8626\n",
      "Epoch 7/10, Batch 1220/1465, Loss: 1.0299\n",
      "Epoch 7/10, Batch 1230/1465, Loss: 0.8583\n",
      "Epoch 7/10, Batch 1240/1465, Loss: 0.8306\n",
      "Epoch 7/10, Batch 1250/1465, Loss: 0.9540\n",
      "Epoch 7/10, Batch 1260/1465, Loss: 0.9795\n",
      "Epoch 7/10, Batch 1270/1465, Loss: 0.9425\n",
      "Epoch 7/10, Batch 1280/1465, Loss: 0.9040\n",
      "Epoch 7/10, Batch 1290/1465, Loss: 0.9955\n",
      "Epoch 7/10, Batch 1300/1465, Loss: 0.9338\n",
      "Epoch 7/10, Batch 1310/1465, Loss: 0.9242\n",
      "Epoch 7/10, Batch 1320/1465, Loss: 0.7769\n",
      "Epoch 7/10, Batch 1330/1465, Loss: 0.6937\n",
      "Epoch 7/10, Batch 1340/1465, Loss: 0.8328\n",
      "Epoch 7/10, Batch 1350/1465, Loss: 0.7306\n",
      "Epoch 7/10, Batch 1360/1465, Loss: 0.9778\n",
      "Epoch 7/10, Batch 1370/1465, Loss: 0.8707\n",
      "Epoch 7/10, Batch 1380/1465, Loss: 0.8492\n",
      "Epoch 7/10, Batch 1390/1465, Loss: 0.8785\n",
      "Epoch 7/10, Batch 1400/1465, Loss: 0.8262\n",
      "Epoch 7/10, Batch 1410/1465, Loss: 0.8387\n",
      "Epoch 7/10, Batch 1420/1465, Loss: 1.0677\n",
      "Epoch 7/10, Batch 1430/1465, Loss: 0.7851\n",
      "Epoch 7/10, Batch 1440/1465, Loss: 0.9083\n",
      "Epoch 7/10, Batch 1450/1465, Loss: 1.0314\n",
      "Epoch 7/10, Batch 1460/1465, Loss: 0.6694\n",
      "Epoch [7/10], Average Loss: 0.8731\n",
      "Epoch 8/10, Batch 10/1465, Loss: 0.8672\n",
      "Epoch 8/10, Batch 20/1465, Loss: 1.0602\n",
      "Epoch 8/10, Batch 30/1465, Loss: 0.7209\n",
      "Epoch 8/10, Batch 40/1465, Loss: 0.8076\n",
      "Epoch 8/10, Batch 50/1465, Loss: 0.6995\n",
      "Epoch 8/10, Batch 60/1465, Loss: 0.7821\n",
      "Epoch 8/10, Batch 70/1465, Loss: 0.7711\n",
      "Epoch 8/10, Batch 80/1465, Loss: 1.0282\n",
      "Epoch 8/10, Batch 90/1465, Loss: 0.9715\n",
      "Epoch 8/10, Batch 100/1465, Loss: 0.7951\n",
      "Epoch 8/10, Batch 110/1465, Loss: 0.8441\n",
      "Epoch 8/10, Batch 120/1465, Loss: 0.9723\n",
      "Epoch 8/10, Batch 130/1465, Loss: 0.8094\n",
      "Epoch 8/10, Batch 140/1465, Loss: 0.8896\n",
      "Epoch 8/10, Batch 150/1465, Loss: 0.9332\n",
      "Epoch 8/10, Batch 160/1465, Loss: 0.7784\n",
      "Epoch 8/10, Batch 170/1465, Loss: 1.0810\n",
      "Epoch 8/10, Batch 180/1465, Loss: 0.9165\n",
      "Epoch 8/10, Batch 190/1465, Loss: 0.8610\n",
      "Epoch 8/10, Batch 200/1465, Loss: 0.8153\n",
      "Epoch 8/10, Batch 210/1465, Loss: 0.9156\n",
      "Epoch 8/10, Batch 220/1465, Loss: 0.6281\n",
      "Epoch 8/10, Batch 230/1465, Loss: 0.6604\n",
      "Epoch 8/10, Batch 240/1465, Loss: 0.9165\n",
      "Epoch 8/10, Batch 250/1465, Loss: 0.6911\n",
      "Epoch 8/10, Batch 260/1465, Loss: 0.6758\n",
      "Epoch 8/10, Batch 270/1465, Loss: 0.6125\n",
      "Epoch 8/10, Batch 280/1465, Loss: 0.7673\n",
      "Epoch 8/10, Batch 290/1465, Loss: 0.8323\n",
      "Epoch 8/10, Batch 300/1465, Loss: 1.0761\n",
      "Epoch 8/10, Batch 310/1465, Loss: 0.8216\n",
      "Epoch 8/10, Batch 320/1465, Loss: 0.8701\n",
      "Epoch 8/10, Batch 330/1465, Loss: 0.7816\n",
      "Epoch 8/10, Batch 340/1465, Loss: 0.8993\n",
      "Epoch 8/10, Batch 350/1465, Loss: 1.1844\n",
      "Epoch 8/10, Batch 360/1465, Loss: 0.7589\n",
      "Epoch 8/10, Batch 370/1465, Loss: 0.7858\n",
      "Epoch 8/10, Batch 380/1465, Loss: 1.0186\n",
      "Epoch 8/10, Batch 390/1465, Loss: 1.0010\n",
      "Epoch 8/10, Batch 400/1465, Loss: 0.7711\n",
      "Epoch 8/10, Batch 410/1465, Loss: 0.8611\n",
      "Epoch 8/10, Batch 420/1465, Loss: 0.8768\n",
      "Epoch 8/10, Batch 430/1465, Loss: 0.8833\n",
      "Epoch 8/10, Batch 440/1465, Loss: 0.8652\n",
      "Epoch 8/10, Batch 450/1465, Loss: 1.0002\n",
      "Epoch 8/10, Batch 460/1465, Loss: 0.7080\n",
      "Epoch 8/10, Batch 470/1465, Loss: 0.8215\n",
      "Epoch 8/10, Batch 480/1465, Loss: 1.0681\n",
      "Epoch 8/10, Batch 490/1465, Loss: 0.6090\n",
      "Epoch 8/10, Batch 500/1465, Loss: 0.9055\n",
      "Epoch 8/10, Batch 510/1465, Loss: 0.7753\n",
      "Epoch 8/10, Batch 520/1465, Loss: 0.6862\n",
      "Epoch 8/10, Batch 530/1465, Loss: 0.8863\n",
      "Epoch 8/10, Batch 540/1465, Loss: 0.8475\n",
      "Epoch 8/10, Batch 550/1465, Loss: 0.8107\n",
      "Epoch 8/10, Batch 560/1465, Loss: 0.8322\n",
      "Epoch 8/10, Batch 570/1465, Loss: 0.9304\n",
      "Epoch 8/10, Batch 580/1465, Loss: 0.8875\n",
      "Epoch 8/10, Batch 590/1465, Loss: 0.7168\n",
      "Epoch 8/10, Batch 600/1465, Loss: 0.7076\n",
      "Epoch 8/10, Batch 610/1465, Loss: 0.7192\n",
      "Epoch 8/10, Batch 620/1465, Loss: 0.8443\n",
      "Epoch 8/10, Batch 630/1465, Loss: 0.9265\n",
      "Epoch 8/10, Batch 640/1465, Loss: 1.0144\n",
      "Epoch 8/10, Batch 650/1465, Loss: 0.6731\n",
      "Epoch 8/10, Batch 660/1465, Loss: 0.8514\n",
      "Epoch 8/10, Batch 670/1465, Loss: 1.0036\n",
      "Epoch 8/10, Batch 680/1465, Loss: 0.8433\n",
      "Epoch 8/10, Batch 690/1465, Loss: 1.1395\n",
      "Epoch 8/10, Batch 700/1465, Loss: 0.8236\n",
      "Epoch 8/10, Batch 710/1465, Loss: 0.7383\n",
      "Epoch 8/10, Batch 720/1465, Loss: 0.7683\n",
      "Epoch 8/10, Batch 730/1465, Loss: 0.7827\n",
      "Epoch 8/10, Batch 740/1465, Loss: 0.8818\n",
      "Epoch 8/10, Batch 750/1465, Loss: 0.9997\n",
      "Epoch 8/10, Batch 760/1465, Loss: 1.0286\n",
      "Epoch 8/10, Batch 770/1465, Loss: 0.8389\n",
      "Epoch 8/10, Batch 780/1465, Loss: 0.8718\n",
      "Epoch 8/10, Batch 790/1465, Loss: 0.8525\n",
      "Epoch 8/10, Batch 800/1465, Loss: 0.7972\n",
      "Epoch 8/10, Batch 810/1465, Loss: 0.8511\n",
      "Epoch 8/10, Batch 820/1465, Loss: 0.7106\n",
      "Epoch 8/10, Batch 830/1465, Loss: 0.7977\n",
      "Epoch 8/10, Batch 840/1465, Loss: 0.8547\n",
      "Epoch 8/10, Batch 850/1465, Loss: 0.6902\n",
      "Epoch 8/10, Batch 860/1465, Loss: 0.9533\n",
      "Epoch 8/10, Batch 870/1465, Loss: 1.2217\n",
      "Epoch 8/10, Batch 880/1465, Loss: 0.6953\n",
      "Epoch 8/10, Batch 890/1465, Loss: 0.8644\n",
      "Epoch 8/10, Batch 900/1465, Loss: 0.9585\n",
      "Epoch 8/10, Batch 910/1465, Loss: 0.7642\n",
      "Epoch 8/10, Batch 920/1465, Loss: 0.8536\n",
      "Epoch 8/10, Batch 930/1465, Loss: 0.7437\n",
      "Epoch 8/10, Batch 940/1465, Loss: 0.7656\n",
      "Epoch 8/10, Batch 950/1465, Loss: 0.8303\n",
      "Epoch 8/10, Batch 960/1465, Loss: 0.9377\n",
      "Epoch 8/10, Batch 970/1465, Loss: 0.7603\n",
      "Epoch 8/10, Batch 980/1465, Loss: 0.6936\n",
      "Epoch 8/10, Batch 990/1465, Loss: 0.9086\n",
      "Epoch 8/10, Batch 1000/1465, Loss: 0.7209\n",
      "Epoch 8/10, Batch 1010/1465, Loss: 0.7563\n",
      "Epoch 8/10, Batch 1020/1465, Loss: 0.8290\n",
      "Epoch 8/10, Batch 1030/1465, Loss: 0.9213\n",
      "Epoch 8/10, Batch 1040/1465, Loss: 0.6798\n",
      "Epoch 8/10, Batch 1050/1465, Loss: 0.7986\n",
      "Epoch 8/10, Batch 1060/1465, Loss: 0.8142\n",
      "Epoch 8/10, Batch 1070/1465, Loss: 1.1991\n",
      "Epoch 8/10, Batch 1080/1465, Loss: 0.8036\n",
      "Epoch 8/10, Batch 1090/1465, Loss: 0.7778\n",
      "Epoch 8/10, Batch 1100/1465, Loss: 1.0484\n",
      "Epoch 8/10, Batch 1110/1465, Loss: 0.9073\n",
      "Epoch 8/10, Batch 1120/1465, Loss: 0.9501\n",
      "Epoch 8/10, Batch 1130/1465, Loss: 0.8074\n",
      "Epoch 8/10, Batch 1140/1465, Loss: 0.9002\n",
      "Epoch 8/10, Batch 1150/1465, Loss: 0.7815\n",
      "Epoch 8/10, Batch 1160/1465, Loss: 0.8080\n",
      "Epoch 8/10, Batch 1170/1465, Loss: 0.8355\n",
      "Epoch 8/10, Batch 1180/1465, Loss: 0.6823\n",
      "Epoch 8/10, Batch 1190/1465, Loss: 0.8529\n",
      "Epoch 8/10, Batch 1200/1465, Loss: 0.9196\n",
      "Epoch 8/10, Batch 1210/1465, Loss: 0.8756\n",
      "Epoch 8/10, Batch 1220/1465, Loss: 1.2018\n",
      "Epoch 8/10, Batch 1230/1465, Loss: 0.9056\n",
      "Epoch 8/10, Batch 1240/1465, Loss: 0.7894\n",
      "Epoch 8/10, Batch 1250/1465, Loss: 0.8212\n",
      "Epoch 8/10, Batch 1260/1465, Loss: 0.7838\n",
      "Epoch 8/10, Batch 1270/1465, Loss: 0.7220\n",
      "Epoch 8/10, Batch 1280/1465, Loss: 0.9210\n",
      "Epoch 8/10, Batch 1290/1465, Loss: 0.8278\n",
      "Epoch 8/10, Batch 1300/1465, Loss: 0.8394\n",
      "Epoch 8/10, Batch 1310/1465, Loss: 0.9478\n",
      "Epoch 8/10, Batch 1320/1465, Loss: 0.7373\n",
      "Epoch 8/10, Batch 1330/1465, Loss: 0.7591\n",
      "Epoch 8/10, Batch 1340/1465, Loss: 0.7518\n",
      "Epoch 8/10, Batch 1350/1465, Loss: 1.0707\n",
      "Epoch 8/10, Batch 1360/1465, Loss: 0.8540\n",
      "Epoch 8/10, Batch 1370/1465, Loss: 0.9565\n",
      "Epoch 8/10, Batch 1380/1465, Loss: 0.7874\n",
      "Epoch 8/10, Batch 1390/1465, Loss: 0.7396\n",
      "Epoch 8/10, Batch 1400/1465, Loss: 0.8958\n",
      "Epoch 8/10, Batch 1410/1465, Loss: 0.8241\n",
      "Epoch 8/10, Batch 1420/1465, Loss: 0.9092\n",
      "Epoch 8/10, Batch 1430/1465, Loss: 0.8088\n",
      "Epoch 8/10, Batch 1440/1465, Loss: 0.9234\n",
      "Epoch 8/10, Batch 1450/1465, Loss: 0.7579\n",
      "Epoch 8/10, Batch 1460/1465, Loss: 0.9134\n",
      "Epoch [8/10], Average Loss: 0.8623\n",
      "Epoch 9/10, Batch 10/1465, Loss: 0.6889\n",
      "Epoch 9/10, Batch 20/1465, Loss: 0.7728\n",
      "Epoch 9/10, Batch 30/1465, Loss: 0.9216\n",
      "Epoch 9/10, Batch 40/1465, Loss: 0.7671\n",
      "Epoch 9/10, Batch 50/1465, Loss: 0.8542\n",
      "Epoch 9/10, Batch 60/1465, Loss: 0.8034\n",
      "Epoch 9/10, Batch 70/1465, Loss: 0.7530\n",
      "Epoch 9/10, Batch 80/1465, Loss: 0.9100\n",
      "Epoch 9/10, Batch 90/1465, Loss: 0.7486\n",
      "Epoch 9/10, Batch 100/1465, Loss: 0.8057\n",
      "Epoch 9/10, Batch 110/1465, Loss: 0.9595\n",
      "Epoch 9/10, Batch 120/1465, Loss: 0.8076\n",
      "Epoch 9/10, Batch 130/1465, Loss: 0.8973\n",
      "Epoch 9/10, Batch 140/1465, Loss: 0.7676\n",
      "Epoch 9/10, Batch 150/1465, Loss: 0.8194\n",
      "Epoch 9/10, Batch 160/1465, Loss: 0.8846\n",
      "Epoch 9/10, Batch 170/1465, Loss: 1.0673\n",
      "Epoch 9/10, Batch 180/1465, Loss: 0.9459\n",
      "Epoch 9/10, Batch 190/1465, Loss: 0.9814\n",
      "Epoch 9/10, Batch 200/1465, Loss: 0.7472\n",
      "Epoch 9/10, Batch 210/1465, Loss: 0.8720\n",
      "Epoch 9/10, Batch 220/1465, Loss: 0.9242\n",
      "Epoch 9/10, Batch 230/1465, Loss: 0.7923\n",
      "Epoch 9/10, Batch 240/1465, Loss: 1.1616\n",
      "Epoch 9/10, Batch 250/1465, Loss: 0.9827\n",
      "Epoch 9/10, Batch 260/1465, Loss: 0.7154\n",
      "Epoch 9/10, Batch 270/1465, Loss: 0.7980\n",
      "Epoch 9/10, Batch 280/1465, Loss: 1.0250\n",
      "Epoch 9/10, Batch 290/1465, Loss: 0.8541\n",
      "Epoch 9/10, Batch 300/1465, Loss: 0.7197\n",
      "Epoch 9/10, Batch 310/1465, Loss: 0.7680\n",
      "Epoch 9/10, Batch 320/1465, Loss: 0.7733\n",
      "Epoch 9/10, Batch 330/1465, Loss: 0.6215\n",
      "Epoch 9/10, Batch 340/1465, Loss: 0.9099\n",
      "Epoch 9/10, Batch 350/1465, Loss: 0.7171\n",
      "Epoch 9/10, Batch 360/1465, Loss: 0.9070\n",
      "Epoch 9/10, Batch 370/1465, Loss: 0.9647\n",
      "Epoch 9/10, Batch 380/1465, Loss: 0.8853\n",
      "Epoch 9/10, Batch 390/1465, Loss: 0.7841\n",
      "Epoch 9/10, Batch 400/1465, Loss: 1.1479\n",
      "Epoch 9/10, Batch 410/1465, Loss: 0.9471\n",
      "Epoch 9/10, Batch 420/1465, Loss: 1.0670\n",
      "Epoch 9/10, Batch 430/1465, Loss: 0.7235\n",
      "Epoch 9/10, Batch 440/1465, Loss: 0.8125\n",
      "Epoch 9/10, Batch 450/1465, Loss: 0.8535\n",
      "Epoch 9/10, Batch 460/1465, Loss: 0.8623\n",
      "Epoch 9/10, Batch 470/1465, Loss: 0.9110\n",
      "Epoch 9/10, Batch 480/1465, Loss: 0.8110\n",
      "Epoch 9/10, Batch 490/1465, Loss: 0.9376\n",
      "Epoch 9/10, Batch 500/1465, Loss: 0.8920\n",
      "Epoch 9/10, Batch 510/1465, Loss: 0.7784\n",
      "Epoch 9/10, Batch 520/1465, Loss: 0.5480\n",
      "Epoch 9/10, Batch 530/1465, Loss: 0.8639\n",
      "Epoch 9/10, Batch 540/1465, Loss: 0.9255\n",
      "Epoch 9/10, Batch 550/1465, Loss: 0.7970\n",
      "Epoch 9/10, Batch 560/1465, Loss: 0.7877\n",
      "Epoch 9/10, Batch 570/1465, Loss: 0.8091\n",
      "Epoch 9/10, Batch 580/1465, Loss: 0.9966\n",
      "Epoch 9/10, Batch 590/1465, Loss: 0.7900\n",
      "Epoch 9/10, Batch 600/1465, Loss: 0.8702\n",
      "Epoch 9/10, Batch 610/1465, Loss: 0.8269\n",
      "Epoch 9/10, Batch 620/1465, Loss: 0.9759\n",
      "Epoch 9/10, Batch 630/1465, Loss: 0.6952\n",
      "Epoch 9/10, Batch 640/1465, Loss: 0.8152\n",
      "Epoch 9/10, Batch 650/1465, Loss: 0.9681\n",
      "Epoch 9/10, Batch 660/1465, Loss: 0.8232\n",
      "Epoch 9/10, Batch 670/1465, Loss: 1.0903\n",
      "Epoch 9/10, Batch 680/1465, Loss: 0.7473\n",
      "Epoch 9/10, Batch 690/1465, Loss: 0.7769\n",
      "Epoch 9/10, Batch 700/1465, Loss: 1.0009\n",
      "Epoch 9/10, Batch 710/1465, Loss: 0.9588\n",
      "Epoch 9/10, Batch 720/1465, Loss: 0.7607\n",
      "Epoch 9/10, Batch 730/1465, Loss: 0.8425\n",
      "Epoch 9/10, Batch 740/1465, Loss: 0.7926\n",
      "Epoch 9/10, Batch 750/1465, Loss: 0.9468\n",
      "Epoch 9/10, Batch 760/1465, Loss: 0.9139\n",
      "Epoch 9/10, Batch 770/1465, Loss: 0.8179\n",
      "Epoch 9/10, Batch 780/1465, Loss: 0.7131\n",
      "Epoch 9/10, Batch 790/1465, Loss: 0.8675\n",
      "Epoch 9/10, Batch 800/1465, Loss: 1.0163\n",
      "Epoch 9/10, Batch 810/1465, Loss: 0.7769\n",
      "Epoch 9/10, Batch 820/1465, Loss: 0.9512\n",
      "Epoch 9/10, Batch 830/1465, Loss: 0.7924\n",
      "Epoch 9/10, Batch 840/1465, Loss: 0.8794\n",
      "Epoch 9/10, Batch 850/1465, Loss: 0.7649\n",
      "Epoch 9/10, Batch 860/1465, Loss: 0.8524\n",
      "Epoch 9/10, Batch 870/1465, Loss: 1.0567\n",
      "Epoch 9/10, Batch 880/1465, Loss: 0.9015\n",
      "Epoch 9/10, Batch 890/1465, Loss: 0.8787\n",
      "Epoch 9/10, Batch 900/1465, Loss: 0.5506\n",
      "Epoch 9/10, Batch 910/1465, Loss: 0.9905\n",
      "Epoch 9/10, Batch 920/1465, Loss: 0.7617\n",
      "Epoch 9/10, Batch 930/1465, Loss: 0.7826\n",
      "Epoch 9/10, Batch 940/1465, Loss: 0.8520\n",
      "Epoch 9/10, Batch 950/1465, Loss: 0.8741\n",
      "Epoch 9/10, Batch 960/1465, Loss: 0.6543\n",
      "Epoch 9/10, Batch 970/1465, Loss: 0.7425\n",
      "Epoch 9/10, Batch 980/1465, Loss: 0.8284\n",
      "Epoch 9/10, Batch 990/1465, Loss: 1.0739\n",
      "Epoch 9/10, Batch 1000/1465, Loss: 0.5925\n",
      "Epoch 9/10, Batch 1010/1465, Loss: 0.9750\n",
      "Epoch 9/10, Batch 1020/1465, Loss: 0.7946\n",
      "Epoch 9/10, Batch 1030/1465, Loss: 0.9050\n",
      "Epoch 9/10, Batch 1040/1465, Loss: 0.8906\n",
      "Epoch 9/10, Batch 1050/1465, Loss: 0.7456\n",
      "Epoch 9/10, Batch 1060/1465, Loss: 0.7971\n",
      "Epoch 9/10, Batch 1070/1465, Loss: 0.8288\n",
      "Epoch 9/10, Batch 1080/1465, Loss: 0.9838\n",
      "Epoch 9/10, Batch 1090/1465, Loss: 0.9718\n",
      "Epoch 9/10, Batch 1100/1465, Loss: 0.7756\n",
      "Epoch 9/10, Batch 1110/1465, Loss: 0.9358\n",
      "Epoch 9/10, Batch 1120/1465, Loss: 0.7147\n",
      "Epoch 9/10, Batch 1130/1465, Loss: 0.9439\n",
      "Epoch 9/10, Batch 1140/1465, Loss: 0.8312\n",
      "Epoch 9/10, Batch 1150/1465, Loss: 0.9071\n",
      "Epoch 9/10, Batch 1160/1465, Loss: 1.1354\n",
      "Epoch 9/10, Batch 1170/1465, Loss: 0.7955\n",
      "Epoch 9/10, Batch 1180/1465, Loss: 0.8078\n",
      "Epoch 9/10, Batch 1190/1465, Loss: 0.8070\n",
      "Epoch 9/10, Batch 1200/1465, Loss: 0.7458\n",
      "Epoch 9/10, Batch 1210/1465, Loss: 0.7341\n",
      "Epoch 9/10, Batch 1220/1465, Loss: 0.9948\n",
      "Epoch 9/10, Batch 1230/1465, Loss: 0.9370\n",
      "Epoch 9/10, Batch 1240/1465, Loss: 0.6279\n",
      "Epoch 9/10, Batch 1250/1465, Loss: 0.7800\n",
      "Epoch 9/10, Batch 1260/1465, Loss: 0.8895\n",
      "Epoch 9/10, Batch 1270/1465, Loss: 0.7810\n",
      "Epoch 9/10, Batch 1280/1465, Loss: 0.9798\n",
      "Epoch 9/10, Batch 1290/1465, Loss: 0.5960\n",
      "Epoch 9/10, Batch 1300/1465, Loss: 0.8341\n",
      "Epoch 9/10, Batch 1310/1465, Loss: 0.8319\n",
      "Epoch 9/10, Batch 1320/1465, Loss: 0.8280\n",
      "Epoch 9/10, Batch 1330/1465, Loss: 0.9970\n",
      "Epoch 9/10, Batch 1340/1465, Loss: 0.9048\n",
      "Epoch 9/10, Batch 1350/1465, Loss: 0.8602\n",
      "Epoch 9/10, Batch 1360/1465, Loss: 1.0650\n",
      "Epoch 9/10, Batch 1370/1465, Loss: 1.0196\n",
      "Epoch 9/10, Batch 1380/1465, Loss: 0.9798\n",
      "Epoch 9/10, Batch 1390/1465, Loss: 0.7948\n",
      "Epoch 9/10, Batch 1400/1465, Loss: 0.9011\n",
      "Epoch 9/10, Batch 1410/1465, Loss: 1.0058\n",
      "Epoch 9/10, Batch 1420/1465, Loss: 0.9414\n",
      "Epoch 9/10, Batch 1430/1465, Loss: 0.9551\n",
      "Epoch 9/10, Batch 1440/1465, Loss: 0.8564\n",
      "Epoch 9/10, Batch 1450/1465, Loss: 0.8287\n",
      "Epoch 9/10, Batch 1460/1465, Loss: 1.0120\n",
      "Epoch [9/10], Average Loss: 0.8571\n",
      "Epoch 10/10, Batch 10/1465, Loss: 0.8295\n",
      "Epoch 10/10, Batch 20/1465, Loss: 0.9596\n",
      "Epoch 10/10, Batch 30/1465, Loss: 0.8229\n",
      "Epoch 10/10, Batch 40/1465, Loss: 0.8302\n",
      "Epoch 10/10, Batch 50/1465, Loss: 0.5485\n",
      "Epoch 10/10, Batch 60/1465, Loss: 0.8498\n",
      "Epoch 10/10, Batch 70/1465, Loss: 0.8922\n",
      "Epoch 10/10, Batch 80/1465, Loss: 0.6466\n",
      "Epoch 10/10, Batch 90/1465, Loss: 0.6452\n",
      "Epoch 10/10, Batch 100/1465, Loss: 1.0537\n",
      "Epoch 10/10, Batch 110/1465, Loss: 0.7195\n",
      "Epoch 10/10, Batch 120/1465, Loss: 0.8935\n",
      "Epoch 10/10, Batch 130/1465, Loss: 0.8142\n",
      "Epoch 10/10, Batch 140/1465, Loss: 0.8651\n",
      "Epoch 10/10, Batch 150/1465, Loss: 0.7921\n",
      "Epoch 10/10, Batch 160/1465, Loss: 0.8986\n",
      "Epoch 10/10, Batch 170/1465, Loss: 0.8466\n",
      "Epoch 10/10, Batch 180/1465, Loss: 0.6381\n",
      "Epoch 10/10, Batch 190/1465, Loss: 0.8881\n",
      "Epoch 10/10, Batch 200/1465, Loss: 0.7556\n",
      "Epoch 10/10, Batch 210/1465, Loss: 0.9494\n",
      "Epoch 10/10, Batch 220/1465, Loss: 0.6343\n",
      "Epoch 10/10, Batch 230/1465, Loss: 1.0899\n",
      "Epoch 10/10, Batch 240/1465, Loss: 0.8545\n",
      "Epoch 10/10, Batch 250/1465, Loss: 0.9786\n",
      "Epoch 10/10, Batch 260/1465, Loss: 0.7603\n",
      "Epoch 10/10, Batch 270/1465, Loss: 0.9124\n",
      "Epoch 10/10, Batch 280/1465, Loss: 0.6751\n",
      "Epoch 10/10, Batch 290/1465, Loss: 0.8286\n",
      "Epoch 10/10, Batch 300/1465, Loss: 0.6884\n",
      "Epoch 10/10, Batch 310/1465, Loss: 0.6939\n",
      "Epoch 10/10, Batch 320/1465, Loss: 0.8885\n",
      "Epoch 10/10, Batch 330/1465, Loss: 0.8072\n",
      "Epoch 10/10, Batch 340/1465, Loss: 0.9111\n",
      "Epoch 10/10, Batch 350/1465, Loss: 0.7309\n",
      "Epoch 10/10, Batch 360/1465, Loss: 0.6534\n",
      "Epoch 10/10, Batch 370/1465, Loss: 0.7772\n",
      "Epoch 10/10, Batch 380/1465, Loss: 0.8013\n",
      "Epoch 10/10, Batch 390/1465, Loss: 0.8131\n",
      "Epoch 10/10, Batch 400/1465, Loss: 0.8698\n",
      "Epoch 10/10, Batch 410/1465, Loss: 0.7373\n",
      "Epoch 10/10, Batch 420/1465, Loss: 0.6489\n",
      "Epoch 10/10, Batch 430/1465, Loss: 0.7760\n",
      "Epoch 10/10, Batch 440/1465, Loss: 0.8398\n",
      "Epoch 10/10, Batch 450/1465, Loss: 0.6686\n",
      "Epoch 10/10, Batch 460/1465, Loss: 0.8147\n",
      "Epoch 10/10, Batch 470/1465, Loss: 0.9151\n",
      "Epoch 10/10, Batch 480/1465, Loss: 0.9696\n",
      "Epoch 10/10, Batch 490/1465, Loss: 0.8774\n",
      "Epoch 10/10, Batch 500/1465, Loss: 0.8147\n",
      "Epoch 10/10, Batch 510/1465, Loss: 0.9542\n",
      "Epoch 10/10, Batch 520/1465, Loss: 1.0194\n",
      "Epoch 10/10, Batch 530/1465, Loss: 0.9398\n",
      "Epoch 10/10, Batch 540/1465, Loss: 0.7725\n",
      "Epoch 10/10, Batch 550/1465, Loss: 0.9360\n",
      "Epoch 10/10, Batch 560/1465, Loss: 0.9346\n",
      "Epoch 10/10, Batch 570/1465, Loss: 0.8325\n",
      "Epoch 10/10, Batch 580/1465, Loss: 0.7823\n",
      "Epoch 10/10, Batch 590/1465, Loss: 0.9304\n",
      "Epoch 10/10, Batch 600/1465, Loss: 0.7935\n",
      "Epoch 10/10, Batch 610/1465, Loss: 0.8173\n",
      "Epoch 10/10, Batch 620/1465, Loss: 0.7992\n",
      "Epoch 10/10, Batch 630/1465, Loss: 0.7374\n",
      "Epoch 10/10, Batch 640/1465, Loss: 0.6287\n",
      "Epoch 10/10, Batch 650/1465, Loss: 0.7460\n",
      "Epoch 10/10, Batch 660/1465, Loss: 0.5624\n",
      "Epoch 10/10, Batch 670/1465, Loss: 0.6588\n",
      "Epoch 10/10, Batch 680/1465, Loss: 0.6708\n",
      "Epoch 10/10, Batch 690/1465, Loss: 0.8077\n",
      "Epoch 10/10, Batch 700/1465, Loss: 0.9108\n",
      "Epoch 10/10, Batch 710/1465, Loss: 0.7812\n",
      "Epoch 10/10, Batch 720/1465, Loss: 0.7218\n",
      "Epoch 10/10, Batch 730/1465, Loss: 0.8045\n",
      "Epoch 10/10, Batch 740/1465, Loss: 0.7006\n",
      "Epoch 10/10, Batch 750/1465, Loss: 0.8233\n",
      "Epoch 10/10, Batch 760/1465, Loss: 0.7158\n",
      "Epoch 10/10, Batch 770/1465, Loss: 0.8593\n",
      "Epoch 10/10, Batch 780/1465, Loss: 1.0817\n",
      "Epoch 10/10, Batch 790/1465, Loss: 0.9004\n",
      "Epoch 10/10, Batch 800/1465, Loss: 0.9202\n",
      "Epoch 10/10, Batch 810/1465, Loss: 0.7226\n",
      "Epoch 10/10, Batch 820/1465, Loss: 0.9154\n",
      "Epoch 10/10, Batch 830/1465, Loss: 0.8163\n",
      "Epoch 10/10, Batch 840/1465, Loss: 0.9286\n",
      "Epoch 10/10, Batch 850/1465, Loss: 0.9015\n",
      "Epoch 10/10, Batch 860/1465, Loss: 0.9628\n",
      "Epoch 10/10, Batch 870/1465, Loss: 0.9576\n",
      "Epoch 10/10, Batch 880/1465, Loss: 0.8935\n",
      "Epoch 10/10, Batch 890/1465, Loss: 1.0298\n",
      "Epoch 10/10, Batch 900/1465, Loss: 0.8534\n",
      "Epoch 10/10, Batch 910/1465, Loss: 0.8901\n",
      "Epoch 10/10, Batch 920/1465, Loss: 0.7641\n",
      "Epoch 10/10, Batch 930/1465, Loss: 0.8815\n",
      "Epoch 10/10, Batch 940/1465, Loss: 0.7477\n",
      "Epoch 10/10, Batch 950/1465, Loss: 0.8392\n",
      "Epoch 10/10, Batch 960/1465, Loss: 0.7944\n",
      "Epoch 10/10, Batch 970/1465, Loss: 0.6920\n",
      "Epoch 10/10, Batch 980/1465, Loss: 0.6519\n",
      "Epoch 10/10, Batch 990/1465, Loss: 0.9296\n",
      "Epoch 10/10, Batch 1000/1465, Loss: 0.8220\n",
      "Epoch 10/10, Batch 1010/1465, Loss: 0.8629\n",
      "Epoch 10/10, Batch 1020/1465, Loss: 1.3120\n",
      "Epoch 10/10, Batch 1030/1465, Loss: 0.6298\n",
      "Epoch 10/10, Batch 1040/1465, Loss: 0.8702\n",
      "Epoch 10/10, Batch 1050/1465, Loss: 0.9159\n",
      "Epoch 10/10, Batch 1060/1465, Loss: 0.7482\n",
      "Epoch 10/10, Batch 1070/1465, Loss: 0.6833\n",
      "Epoch 10/10, Batch 1080/1465, Loss: 0.9801\n",
      "Epoch 10/10, Batch 1090/1465, Loss: 0.9293\n",
      "Epoch 10/10, Batch 1100/1465, Loss: 0.9503\n",
      "Epoch 10/10, Batch 1110/1465, Loss: 0.8263\n",
      "Epoch 10/10, Batch 1120/1465, Loss: 1.0281\n",
      "Epoch 10/10, Batch 1130/1465, Loss: 0.7171\n",
      "Epoch 10/10, Batch 1140/1465, Loss: 0.7800\n",
      "Epoch 10/10, Batch 1150/1465, Loss: 0.7623\n",
      "Epoch 10/10, Batch 1160/1465, Loss: 0.8103\n",
      "Epoch 10/10, Batch 1170/1465, Loss: 0.8906\n",
      "Epoch 10/10, Batch 1180/1465, Loss: 0.7806\n",
      "Epoch 10/10, Batch 1190/1465, Loss: 0.9364\n",
      "Epoch 10/10, Batch 1200/1465, Loss: 0.7984\n",
      "Epoch 10/10, Batch 1210/1465, Loss: 0.8275\n",
      "Epoch 10/10, Batch 1220/1465, Loss: 0.7883\n",
      "Epoch 10/10, Batch 1230/1465, Loss: 1.0174\n",
      "Epoch 10/10, Batch 1240/1465, Loss: 1.0648\n",
      "Epoch 10/10, Batch 1250/1465, Loss: 0.9175\n",
      "Epoch 10/10, Batch 1260/1465, Loss: 0.7527\n",
      "Epoch 10/10, Batch 1270/1465, Loss: 0.9047\n",
      "Epoch 10/10, Batch 1280/1465, Loss: 0.8136\n",
      "Epoch 10/10, Batch 1290/1465, Loss: 0.9549\n",
      "Epoch 10/10, Batch 1300/1465, Loss: 1.0488\n",
      "Epoch 10/10, Batch 1310/1465, Loss: 1.0179\n",
      "Epoch 10/10, Batch 1320/1465, Loss: 0.7242\n",
      "Epoch 10/10, Batch 1330/1465, Loss: 0.7912\n",
      "Epoch 10/10, Batch 1340/1465, Loss: 1.0321\n",
      "Epoch 10/10, Batch 1350/1465, Loss: 0.8917\n",
      "Epoch 10/10, Batch 1360/1465, Loss: 0.7785\n",
      "Epoch 10/10, Batch 1370/1465, Loss: 0.9560\n",
      "Epoch 10/10, Batch 1380/1465, Loss: 0.7936\n",
      "Epoch 10/10, Batch 1390/1465, Loss: 0.9602\n",
      "Epoch 10/10, Batch 1400/1465, Loss: 0.7497\n",
      "Epoch 10/10, Batch 1410/1465, Loss: 0.9371\n",
      "Epoch 10/10, Batch 1420/1465, Loss: 0.8037\n",
      "Epoch 10/10, Batch 1430/1465, Loss: 0.8952\n",
      "Epoch 10/10, Batch 1440/1465, Loss: 1.0237\n",
      "Epoch 10/10, Batch 1450/1465, Loss: 1.0550\n",
      "Epoch 10/10, Batch 1460/1465, Loss: 0.7197\n",
      "Epoch [10/10], Average Loss: 0.8496\n",
      "Finished Training\n",
      "Accuracy: 62.70969394288641%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"netflix_reviews.csv\")  # 파일 불러오기\n",
    "df = df.iloc[:,0:5]\n",
    "\n",
    "# 전처리 함수\n",
    "import re\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, float):\n",
    "        return \"\"\n",
    "    text = text.lower()  # 대문자를 소문자로\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # 구두점 제거\n",
    "    text = re.sub(r'\\d+', '', text)  # 숫자 제거\n",
    "    text = text.strip()  # 띄어쓰기 제외하고 빈 칸 제거\n",
    "    return text\n",
    "\n",
    "\n",
    "df['reviewId'] = df['reviewId'].apply(preprocess_text)\n",
    "df['userName'] = df['userName'].apply(preprocess_text)\n",
    "df['content'] = df['content'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "#\n",
    "reviews = df['content'].tolist()  # 'content'를 리스트로 변환\n",
    "ratings = df['score'].tolist()    # 'score'를 리스트로 변환\n",
    "\n",
    "\n",
    "\n",
    "# 라벨을 정수형으로 변환 (필수적인 과정)\n",
    "label_encoder = LabelEncoder()\n",
    "ratings = label_encoder.fit_transform(ratings)  # 평점 정수형으로 변환\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, ratings, text_pipeline, label_pipeline):\n",
    "        self.reviews = reviews\n",
    "        self.ratings = ratings\n",
    "        self.text_pipeline = text_pipeline\n",
    "        self.label_pipeline = label_pipeline\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.text_pipeline(self.reviews[idx])\n",
    "        rating = self.label_pipeline(self.ratings[idx])\n",
    "        return torch.tensor(review), torch.tensor(rating)\n",
    "\n",
    "# 토크나이저 정의 (기본 영어 토크나이저)\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# 어휘 사전 생성 함수\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# 어휘 사전 생성\n",
    "vocab = build_vocab_from_iterator(yield_tokens(reviews))\n",
    "\n",
    "\n",
    "# 텍스트 파이프라인 정의 (어휘 사전에 있는 단어만 처리)\n",
    "def text_pipeline(text):\n",
    "    return [vocab[token] for token in tokenizer(text)]\n",
    "\n",
    "# 평점 그대로 사용\n",
    "def label_pipeline(label):\n",
    "    return label  # 이미 숫자형이므로 변환 생략\n",
    "\n",
    "# 데이터를 학습용(train)과 테스트용(test)으로 분리\n",
    "train_reviews, test_reviews, train_ratings, test_ratings = train_test_split(reviews, ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터셋 정의\n",
    "train_dataset = ReviewDataset(train_reviews, train_ratings, text_pipeline, label_pipeline)\n",
    "test_dataset = ReviewDataset(test_reviews, test_ratings, text_pipeline, label_pipeline)\n",
    "\n",
    "# 패딩을 적용하는 함수 정의\n",
    "\n",
    "def collate_fn(batch):\n",
    "    reviews, ratings = zip(*batch)\n",
    "    reviews = pad_sequence([torch.tensor(r, dtype=torch.long) for r in reviews], batch_first=True)  # 정수형 텐서로 변환\n",
    "    ratings = torch.tensor(ratings, dtype=torch.long)  # 평점도 정수형으로 변환\n",
    "    return reviews, ratings\n",
    "# 데이터 로더 정의\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)  # Embedding으로 변경\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return self.fc(hidden[-1])\n",
    "\n",
    "# 하이퍼파라미터 정의\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBED_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(set(ratings))  # 예측할 점수 개수 (평점이 정수형)\n",
    "\n",
    "# 모델 초기화\n",
    "model = LSTMModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  # SGD 에서 Adam으로 변경 lr : 0.01 - > 0.001 / Accuracy: 63% -> 61.59% 다시 0.01\n",
    "\n",
    "# 모델을 CUDA로 이동 (가능한 경우)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 모델 학습 함수 정의\n",
    "def train_model(model, train_dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()  # 학습 모드로 설정\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0  # 에포크마다 손실을 추적\n",
    "        for i, (reviews, ratings) in enumerate(train_dataloader):\n",
    "            reviews, ratings = reviews.to(device), ratings.to(device)  # 데이터를 GPU로 이동\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(reviews)  # 모델에 입력하여 예측값 계산\n",
    "            loss = criterion(outputs, ratings)  # 손실 계산\n",
    "            loss.backward()  # 역전파\n",
    "            optimizer.step()  # 가중치 업데이트\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 배치마다 손실 출력\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, Batch {i+1}/{len(train_dataloader)}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {total_loss/len(train_dataloader):.4f}')\n",
    "    \n",
    "    print(\"Finished Training\")\n",
    "\n",
    "# 모델 학습 실행\n",
    "train_model(model, train_dataloader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "# 모델 평가\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 평가 시에는 기울기 계산을 하지 않음\n",
    "    for reviews, ratings in test_dataloader:\n",
    "        reviews, ratings = reviews.to(device), ratings.to(device)\n",
    "        outputs = model(reviews)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += ratings.size(0)\n",
    "        correct += (predicted == ratings).sum().item()\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c329d1eb-efaa-4818-9597-4ee0919af35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Score: 4\n"
     ]
    }
   ],
   "source": [
    "# 예측 함수\n",
    "def predict_review(model, review, vocab, tokenizer, device):\n",
    "    # 리뷰를 텐서로 변환\n",
    "    tokens = [vocab[token] for token in tokenizer(review)]\n",
    "    review_tensor = torch.tensor(tokens).unsqueeze(0)  # (1, seq_length) 형태로 만듦\n",
    "    \n",
    "    # 텐서를 GPU로 이동\n",
    "    review_tensor = review_tensor.to(device)\n",
    "    \n",
    "    # 모델에 입력하여 예측값 계산\n",
    "    model.eval()  # 평가 모드로 변경\n",
    "    with torch.no_grad():  # 평가 시에는 기울기 계산을 하지 않음\n",
    "        output = model(review_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    \n",
    "    return predicted.item()  # 예측된 평점 반환\n",
    "# 새로운 리뷰에 대한 예측\n",
    "new_review = \"This app is great but has some bugs.\"\n",
    "predicted_score = predict_review(model, new_review, vocab, tokenizer,  device)\n",
    "print(f'Predicted Score: {predicted_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a5803-f49b-4a9c-ae74-56cbc8551655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
